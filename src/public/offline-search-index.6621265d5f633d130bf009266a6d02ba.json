[{"body":"Endpoints Overview Method Endpoint Description GET /agents List all agents POST /agents Create a new agent GET /agents/{id} Get agent details PATCH /agents/{id} Update an agent DELETE /agents/{id} Delete an agent POST /agents/{id}/run Run a command POST /agents/{id}/chat Start a chat session GET /agents/{id}/activity Get activity log List Agents GET /v1/agents Query Parameters Parameter Type Description status string Filter by status: running, paused, error type string Filter by type: infrastructure, security, etc. limit integer Max results (default: 20, max: 100) offset integer Pagination offset Example Request curl -X GET \"https://api.cloud2gether.com/v1/agents?status=running\" \\ -H \"Authorization: Bearer $API_KEY\" Example Response { \"data\": [ { \"id\": \"agent_abc123\", \"name\": \"prod-infra\", \"type\": \"infrastructure\", \"status\": \"running\", \"providers\": [\"aws\", \"gcp\"], \"created_at\": \"2024-01-10T08:00:00Z\", \"last_activity\": \"2024-01-15T10:30:00Z\" }, { \"id\": \"agent_def456\", \"name\": \"security-audit\", \"type\": \"security\", \"status\": \"running\", \"providers\": [\"aws\"], \"created_at\": \"2024-01-12T14:00:00Z\", \"last_activity\": \"2024-01-15T09:15:00Z\" } ], \"meta\": { \"total\": 5, \"limit\": 20, \"offset\": 0 } } Create Agent POST /v1/agents Request Body { \"name\": \"my-agent\", \"type\": \"infrastructure\", \"providers\": [\"aws\"], \"config\": { \"regions\": [\"us-east-1\", \"us-west-2\"], \"discovery_interval\": \"5m\" }, \"policies\": [\"production-safety\"] } Request Fields Field Type Required Description name string Yes Unique agent name type string Yes Agent type providers array Yes Cloud providers to connect config object No Agent configuration policies array No Policy names to apply Example Request curl -X POST https://api.cloud2gether.com/v1/agents \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"cost-optimizer\", \"type\": \"cost\", \"providers\": [\"aws\", \"azure\"] }' Example Response { \"data\": { \"id\": \"agent_xyz789\", \"name\": \"cost-optimizer\", \"type\": \"cost\", \"status\": \"deploying\", \"providers\": [\"aws\", \"azure\"], \"created_at\": \"2024-01-15T10:35:00Z\" } } Get Agent GET /v1/agents/{id} Example Request curl -X GET https://api.cloud2gether.com/v1/agents/agent_abc123 \\ -H \"Authorization: Bearer $API_KEY\" Example Response { \"data\": { \"id\": \"agent_abc123\", \"name\": \"prod-infra\", \"type\": \"infrastructure\", \"status\": \"running\", \"providers\": [\"aws\", \"gcp\"], \"config\": { \"regions\": [\"us-east-1\", \"us-west-2\", \"us-central1\"], \"discovery_interval\": \"5m\", \"proactive_monitoring\": true }, \"policies\": [\"production-safety\"], \"stats\": { \"commands_executed\": 1234, \"resources_managed\": 156, \"uptime_hours\": 720 }, \"created_at\": \"2024-01-10T08:00:00Z\", \"last_activity\": \"2024-01-15T10:30:00Z\" } } Update Agent PATCH /v1/agents/{id} Request Body { \"config\": { \"discovery_interval\": \"10m\" }, \"policies\": [\"production-safety\", \"cost-awareness\"] } Example Request curl -X PATCH https://api.cloud2gether.com/v1/agents/agent_abc123 \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"config\": { \"proactive_monitoring\": false } }' Delete Agent DELETE /v1/agents/{id} Example Request curl -X DELETE https://api.cloud2gether.com/v1/agents/agent_abc123 \\ -H \"Authorization: Bearer $API_KEY\" Response { \"data\": { \"id\": \"agent_abc123\", \"status\": \"deleted\" } } Run Command Execute a command on an agent.\nPOST /v1/agents/{id}/run Request Body { \"command\": \"List all EC2 instances in us-east-1\", \"options\": { \"timeout\": 60, \"format\": \"json\" } } Request Fields Field Type Required Description command string Yes Natural language command options.timeout integer No Timeout in seconds (default: 120) options.format string No Response format: text, json options.dry_run boolean No Simulate without executing Example Request curl -X POST https://api.cloud2gether.com/v1/agents/agent_abc123/run \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"command\": \"Show me all S3 buckets over 100GB\" }' Example Response { \"data\": { \"id\": \"run_abc123\", \"status\": \"completed\", \"command\": \"Show me all S3 buckets over 100GB\", \"result\": { \"text\": \"Found 3 S3 buckets over 100GB:\\n\\n1. data-warehouse (2.4 TB)\\n2. backups-prod (890 GB)\\n3. logs-archive (450 GB)\", \"structured\": { \"buckets\": [ {\"name\": \"data-warehouse\", \"size_gb\": 2400}, {\"name\": \"backups-prod\", \"size_gb\": 890}, {\"name\": \"logs-archive\", \"size_gb\": 450} ] } }, \"duration_ms\": 2340, \"created_at\": \"2024-01-15T10:40:00Z\" } } Start Chat Session Create an interactive chat session with an agent.\nPOST /v1/agents/{id}/chat Request Body { \"message\": \"Hello, what can you help me with?\", \"session_id\": \"optional-session-id\" } Example Request curl -X POST https://api.cloud2gether.com/v1/agents/agent_abc123/chat \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"message\": \"How many EC2 instances are running?\" }' Example Response { \"data\": { \"session_id\": \"chat_xyz789\", \"message\": \"You have 47 EC2 instances currently running across 3 regions:\\n\\n- us-east-1: 28 instances\\n- us-west-2: 12 instances\\n- eu-west-1: 7 instances\\n\\nWould you like more details about any specific region?\", \"context\": { \"regions_mentioned\": [\"us-east-1\", \"us-west-2\", \"eu-west-1\"], \"total_instances\": 47 } } } Continue Conversation curl -X POST https://api.cloud2gether.com/v1/agents/agent_abc123/chat \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"message\": \"Show me the ones in us-east-1\", \"session_id\": \"chat_xyz789\" }' Get Activity Log GET /v1/agents/{id}/activity Query Parameters Parameter Type Description start datetime Start time (ISO 8601) end datetime End time (ISO 8601) type string Filter by type: command, error, system limit integer Max results (default: 50) Example Request curl -X GET \"https://api.cloud2gether.com/v1/agents/agent_abc123/activity?limit=10\" \\ -H \"Authorization: Bearer $API_KEY\" Example Response { \"data\": [ { \"id\": \"act_123\", \"type\": \"command\", \"command\": \"List all S3 buckets\", \"status\": \"completed\", \"user\": \"user@example.com\", \"duration_ms\": 1250, \"timestamp\": \"2024-01-15T10:30:00Z\" }, { \"id\": \"act_122\", \"type\": \"command\", \"command\": \"Check security group rules\", \"status\": \"completed\", \"user\": \"user@example.com\", \"duration_ms\": 890, \"timestamp\": \"2024-01-15T10:25:00Z\" } ], \"meta\": { \"total\": 1234, \"limit\": 10, \"offset\": 0 } } Agent Control Pause Agent POST /v1/agents/{id}/pause Resume Agent POST /v1/agents/{id}/resume Restart Agent POST /v1/agents/{id}/restart Example curl -X POST https://api.cloud2gether.com/v1/agents/agent_abc123/pause \\ -H \"Authorization: Bearer $API_KEY\" Streaming Responses For long-running commands, use Server-Sent Events:\ncurl -X POST https://api.cloud2gether.com/v1/agents/agent_abc123/run \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Accept: text/event-stream\" \\ -H \"Content-Type: application/json\" \\ -d '{\"command\": \"Analyze my infrastructure\"}' Response stream:\nevent: progress data: {\"status\": \"analyzing\", \"message\": \"Scanning EC2 instances...\"} event: progress data: {\"status\": \"analyzing\", \"message\": \"Scanning S3 buckets...\"} event: complete data: {\"result\": \"Analysis complete. Found 156 resources...\"} ","categories":"","description":"Endpoints for managing and interacting with AI agents.\n","excerpt":"Endpoints for managing and interacting with AI agents.\n","ref":"/en/docs/api/agents/","tags":"","title":"Agents API"},{"body":"Welcome to the Cloud2Gether documentation. Here youâ€™ll find everything you need to get started with the agentic DevOps platform and master its capabilities.\nQuick Navigation Getting Started New to Cloud2Gether? Start here to set up your account and deploy your first agent.\nGet Started User Guide Learn how to use Cloud2Gether's features and workflows effectively.\nRead Guide AI Agents Understand how AI agents work and how to leverage them for your infrastructure.\nExplore Agents API Reference Integrate Cloud2Gether into your workflows with our comprehensive API.\nView API Administration Configure settings, manage users, and set up security policies.\nAdmin Docs ","categories":"","description":"","excerpt":"Welcome to the Cloud2Gether documentation. Here youâ€™ll find everything â€¦","ref":"/en/docs/","tags":"","title":"Documentation"},{"body":"Welcome to Cloud2Gether! This guide will help you set up your account and start automating your DevOps workflows with AI-powered agents.\nPrerequisites Before you begin, make sure you have:\nA Cloud2Gether account (sign up here) Access to at least one cloud provider (AWS, Azure, or GCP) Administrative permissions to create API keys or service accounts Quick Start Overview Create your account â€” Sign up and verify your email Connect a cloud provider â€” Add credentials for your infrastructure Deploy your first agent â€” Launch an AI agent to manage your resources Issue your first command â€” Tell the agent what to do Whatâ€™s Next? Installation Set up Cloud2Gether CLI and configure your local environment. [Learn more â†’](installation/) Quick Start Deploy your first agent and run your first automation in 5 minutes. [Learn more â†’](quickstart/) Core Concepts Understand the key concepts behind Cloud2Gether's agentic approach. [Learn more â†’](concepts/) Need Help? Check our FAQ for common questions Join our community on Discord Contact support@cloud2gether.com ","categories":"","description":"Get up and running with Cloud2Gether in minutes. This guide walks you through account setup, connecting your first cloud provider, and deploying your first AI agent.\n","excerpt":"Get up and running with Cloud2Gether in minutes. This guide walks you â€¦","ref":"/en/docs/getting-started/","tags":"","title":"Getting Started"},{"body":"The Infrastructure Agent is your primary interface for managing cloud resources across AWS, Azure, GCP, and Kubernetes.\nCapabilities Category Operations Compute Start, stop, resize, deploy instances Storage Create, attach, snapshot, resize volumes and buckets Networking Manage VPCs, subnets, security groups, load balancers Containers Deploy, scale, update ECS/EKS/GKE workloads Serverless Manage Lambda/Functions, configure triggers Database RDS, DynamoDB, Cloud SQL operations Deployment c2g agent deploy infrastructure \\ --name prod-infra \\ --providers aws,azure,gcp Configuration Options name: prod-infra type: infrastructure providers: - name: aws regions: [us-east-1, us-west-2, eu-west-1] role_arn: arn:aws:iam::123456789:role/Cloud2GetherRole - name: azure subscriptions: [sub-id-1, sub-id-2] - name: gcp projects: [project-1, project-2] - name: kubernetes clusters: [prod-cluster] settings: # Scan interval for resource discovery discovery_interval: 5m # Enable proactive monitoring proactive_monitoring: true # Auto-tag resources managed by this agent auto_tagging: true policies: - production-safety Common Operations Resource Discovery \u003e Show me all resources in us-east-1 Infrastructure Summary for us-east-1: Compute: â€¢ EC2 Instances: 47 (38 running, 9 stopped) â€¢ Lambda Functions: 23 â€¢ ECS Services: 12 Storage: â€¢ S3 Buckets: 15 (2.4 TB total) â€¢ EBS Volumes: 89 (4.2 TB total) â€¢ EFS File Systems: 3 Database: â€¢ RDS Instances: 5 â€¢ DynamoDB Tables: 18 Networking: â€¢ VPCs: 3 â€¢ Load Balancers: 8 â€¢ Security Groups: 45 Instance Management \u003e Start all instances tagged Environment=dev Starting 12 instances in dev environment... âœ“ i-abc123 (web-dev-1) started âœ“ i-def456 (web-dev-2) started âœ“ i-ghi789 (api-dev-1) started ... All 12 instances started successfully. \u003e Resize i-abc123 to m5.large Current: t3.medium (2 vCPU, 4 GB RAM) New: m5.large (2 vCPU, 8 GB RAM) This requires stopping the instance. Estimated downtime: 2-5 minutes Cost impact: +$35/month Proceed? [y/N] Storage Operations \u003e Create a snapshot of all production database volumes Found 5 production database volumes: â€¢ vol-abc123 (db-primary) - 500 GB â€¢ vol-def456 (db-replica-1) - 500 GB â€¢ vol-ghi789 (db-replica-2) - 500 GB â€¢ vol-jkl012 (redis-primary) - 100 GB â€¢ vol-mno345 (redis-replica) - 100 GB Creating snapshots... âœ“ snap-abc123 created for vol-abc123 âœ“ snap-def456 created for vol-def456 ... All 5 snapshots created successfully. Retention: 30 days (per snapshot policy) Networking \u003e Show security group rules allowing SSH from anywhere Found 3 security groups with SSH (port 22) open to 0.0.0.0/0: âš ï¸ sg-abc123 (bastion-sg) Rule: Allow TCP 22 from 0.0.0.0/0 Note: Expected for bastion host ğŸš¨ sg-def456 (web-servers) Rule: Allow TCP 22 from 0.0.0.0/0 Recommendation: Restrict to bastion security group ğŸš¨ sg-ghi789 (database) Rule: Allow TCP 22 from 0.0.0.0/0 Recommendation: Remove or restrict immediately Fix these issues? [y/N] Container Management \u003e Scale the api-service to 10 replicas Current: api-service running 5 replicas Target: 10 replicas Scaling up... â€¢ Added 5 new tasks â€¢ Tasks passing health checks â€¢ Load balancer updated api-service now running 10 replicas. New monthly cost estimate: +$150 Multi-Cloud Operations \u003e Show me all compute resources across all providers AWS (3 regions): â€¢ EC2 Instances: 47 â€¢ Lambda Functions: 23 â€¢ ECS Tasks: 84 Azure (2 subscriptions): â€¢ Virtual Machines: 15 â€¢ Functions: 8 â€¢ Container Instances: 12 GCP (2 projects): â€¢ Compute Engine VMs: 22 â€¢ Cloud Functions: 14 â€¢ Cloud Run Services: 6 Total compute resources: 231 Proactive Monitoring The Infrastructure Agent can monitor and alert on issues:\nmonitoring: rules: - name: low-disk-space condition: disk_usage \u003e 80% action: alert channel: \"#ops\" - name: stopped-production condition: instance.state == stopped \u0026\u0026 instance.tags.Environment == production action: alert severity: high - name: orphaned-volumes condition: volume.attached == false \u0026\u0026 volume.age \u003e 7d action: report schedule: weekly Automation Examples Auto-Scaling name: Scale Based on Queue trigger: type: cloudwatch metric: ApproximateNumberOfMessages threshold: 1000 queue: processing-queue agent: prod-infra steps: - command: \"Scale processing-workers to handle queue backlog\" - wait: 10m - command: \"Check if queue is draining properly\" Disaster Recovery name: Failover to DR Region trigger: manual agent: prod-infra inputs: - name: confirm_failover type: boolean required: true steps: - if: \"{{ .inputs.confirm_failover }}\" then: - command: \"Promote RDS read replica in us-west-2 to primary\" - command: \"Update Route 53 to point to us-west-2\" - command: \"Scale up us-west-2 instances to match us-east-1\" - notify: channel: \"#incidents\" message: \"Failover to us-west-2 complete\" Permissions Required AWS IAM Policy { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ec2:*\", \"s3:*\", \"rds:*\", \"ecs:*\", \"lambda:*\", \"elasticloadbalancing:*\" ], \"Resource\": \"*\" } ] } For least-privilege, customize based on your needs. See Security Best Practices.\nTroubleshooting Agent Canâ€™t See Resources # Check provider connection c2g provider test aws # Verify permissions c2g agent permissions prod-infra --provider aws Actions Failing # View recent errors c2g agent logs prod-infra --level error # Check policy restrictions c2g agent policies prod-infra ","categories":"","description":"Manage compute, storage, networking, and other cloud resources.\n","excerpt":"Manage compute, storage, networking, and other cloud resources.\n","ref":"/en/docs/ai-agents/infrastructure/","tags":"","title":"Infrastructure Agent"},{"body":"Installing the CLI The Cloud2Gether CLI (c2g) is the primary way to interact with the platform from your terminal.\nmacOS Using Homebrew:\nbrew tap cloud2gether/tap brew install cloud2gether Or download the binary directly:\ncurl -sSL https://get.cloud2gether.com | sh Linux Using the install script:\ncurl -sSL https://get.cloud2gether.com | sh Or using apt (Debian/Ubuntu):\n# Add the Cloud2Gether repository curl -fsSL https://packages.cloud2gether.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud2gether.gpg echo \"deb [signed-by=/usr/share/keyrings/cloud2gether.gpg] https://packages.cloud2gether.com/apt stable main\" | sudo tee /etc/apt/sources.list.d/cloud2gether.list # Install sudo apt update sudo apt install cloud2gether Windows Using winget:\nwinget install Cloud2Gether.CLI Or download from the releases page.\nVerifying Installation After installation, verify the CLI is working:\nc2g version You should see output like:\nCloud2Gether CLI v1.0.0 Build: 2024-01-15 Authentication Log in to your Cloud2Gether account:\nc2g auth login This will open a browser window for authentication. After logging in, youâ€™ll be redirected back to the terminal.\nAPI Key Authentication For CI/CD environments or scripts, use an API key:\nexport C2G_API_KEY=\"your-api-key-here\" c2g auth verify Generate API keys in the Cloud2Gether Dashboard.\nConfiguration The CLI stores configuration in ~/.cloud2gether/config.yaml. You can also set options via environment variables:\nEnvironment Variable Description C2G_API_KEY API key for authentication C2G_WORKSPACE Default workspace ID C2G_REGION Preferred region for agent deployment C2G_LOG_LEVEL Log verbosity (debug, info, warn, error) Next Steps Now that you have the CLI installed:\nConnect your first cloud provider Deploy your first agent Learn about core concepts ","categories":"","description":"Install the Cloud2Gether CLI and set up your development environment.\n","excerpt":"Install the Cloud2Gether CLI and set up your development environment.\n","ref":"/en/docs/getting-started/installation/","tags":"","title":"Installation"},{"body":"Overview Cloud2Gether uses role-based access control (RBAC) to manage permissions. Users can be added individually or through SSO integration.\nRoles Built-in Roles Role Description Permissions Owner Full control All permissions, billing, delete workspace Admin Administrative access Manage users, agents, policies, providers Operator Day-to-day operations Run commands, manage workflows, view resources Viewer Read-only access View agents, resources, logs Role Permissions Matrix Permission Owner Admin Operator Viewer View resources âœ“ âœ“ âœ“ âœ“ Run agent commands âœ“ âœ“ âœ“ âœ— Create/modify agents âœ“ âœ“ âœ— âœ— Manage policies âœ“ âœ“ âœ— âœ— Manage users âœ“ âœ“ âœ— âœ— Manage providers âœ“ âœ“ âœ— âœ— View audit logs âœ“ âœ“ âœ“ âœ“ Manage billing âœ“ âœ— âœ— âœ— Delete workspace âœ“ âœ— âœ— âœ— Adding Users Via Dashboard Go to Settings â†’ Users Click Invite User Enter email address Select role Click Send Invite Via CLI c2g user invite user@example.com --role operator Via API curl -X POST https://api.cloud2gether.com/v1/users/invites \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"email\": \"user@example.com\", \"role\": \"operator\" }' Managing Users List Users c2g user list Update Role c2g user update user@example.com --role admin Remove User c2g user remove user@example.com View User Activity c2g user activity user@example.com --last 7d Custom Roles Create roles with specific permissions:\n# custom-role.yaml name: deployment-manager description: Can manage deployments but not infrastructure permissions: agents: - view - run_commands workflows: - view - create - update - run resources: - view deployments: - view - create - rollback c2g role create -f custom-role.yaml c2g user update user@example.com --role deployment-manager SSO Configuration Cloud2Gether supports SAML 2.0 and OIDC for single sign-on.\nSAML Setup Go to Settings â†’ Authentication â†’ SSO Select SAML Configure: Setting Value Entity ID https://auth.cloud2gether.com/saml/your-workspace ACS URL https://auth.cloud2gether.com/saml/your-workspace/acs Sign-on URL Your IdPâ€™s SSO URL Certificate Your IdPâ€™s signing certificate OIDC Setup Go to Settings â†’ Authentication â†’ SSO Select OIDC Configure: Setting Description Client ID From your IdP Client Secret From your IdP Issuer URL Your IdPâ€™s issuer URL Scopes openid email profile Supported Identity Providers Okta Azure AD Google Workspace OneLogin Auth0 Ping Identity Role Mapping Map IdP groups to Cloud2Gether roles:\nrole_mappings: - idp_group: \"cloud2gether-admins\" c2g_role: admin - idp_group: \"cloud2gether-operators\" c2g_role: operator - idp_group: \"cloud2gether-viewers\" c2g_role: viewer Multi-Factor Authentication Enforce MFA Require MFA for all users:\nGo to Settings â†’ Security Enable Require MFA Set grace period for existing users Supported MFA Methods Authenticator apps (TOTP) Security keys (WebAuthn) SMS (not recommended) API Keys Users can generate personal API keys:\nc2g auth create-key --name \"CI/CD Pipeline\" --expires 90d Administrators can view all API keys:\nc2g admin api-keys list Revoke a key:\nc2g admin api-keys revoke key_abc123 Teams (Enterprise) Organize users into teams for easier management:\n# Create a team c2g team create backend-team # Add members c2g team add-member backend-team user@example.com # Assign team to resources c2g agent update prod-infra --team backend-team Session Management View Active Sessions c2g admin sessions list --user user@example.com Terminate Sessions # Terminate specific session c2g admin sessions terminate session_abc123 # Terminate all sessions for a user c2g admin sessions terminate-all --user user@example.com Session Policies Configure session settings:\nSetting Description Default Session timeout Idle timeout 24 hours Max session duration Absolute timeout 7 days Concurrent sessions Max per user Unlimited Best Practices Use SSO â€” Centralize authentication with your identity provider Enforce MFA â€” Require multi-factor authentication Least privilege â€” Assign minimum necessary permissions Review regularly â€” Audit user access quarterly Use teams â€” Organize users for easier management Rotate API keys â€” Set expiration on all API keys ","categories":"","description":"Add team members, configure roles, and set up single sign-on.\n","excerpt":"Add team members, configure roles, and set up single sign-on.\n","ref":"/en/docs/admin/users/","tags":"","title":"User Management"},{"body":"Agent Interaction Methods You can communicate with Cloud2Gether agents in several ways:\nCLI Interactive Mode Start a chat session with an agent:\nc2g chat my-agent This opens a REPL where you can have a conversation:\nCloud2Gether Agent: my-agent (infrastructure) Type 'exit' to quit, 'help' for commands \u003e What EC2 instances are running? Found 12 running EC2 instances across 3 regions: us-east-1 (7 instances): â€¢ i-abc123 - web-server-1 (t3.medium) - running 45 days â€¢ i-def456 - web-server-2 (t3.medium) - running 45 days ... \u003e Show me the most expensive ones Top 5 instances by cost (last 30 days): 1. i-xyz789 - ml-training (p3.2xlarge) - $2,847 2. i-abc123 - database-primary (r5.2xlarge) - $1,234 ... CLI Single Command Run a single command and get the result:\nc2g run my-agent \"List all S3 buckets over 100GB\" Dashboard Use the web interface at app.cloud2gether.com:\nNavigate to Agents in the sidebar Click on your agent Use the chat interface Slack Integration After configuring Slack integration:\n@cloud2gether list all unhealthy ECS services Writing Effective Commands Agents understand natural language, but clear commands get better results.\nBe Specific Less Effective More Effective â€œShow me instancesâ€ â€œShow me EC2 instances in us-east-1 that are runningâ€ â€œWhatâ€™s expensive?â€ â€œWhich resources cost more than $100/month?â€ â€œDeploy the appâ€ â€œDeploy the frontend service to the staging ECS clusterâ€ Provide Context Agents remember conversation context, so you can build on previous queries:\n\u003e Show me all Lambda functions (agent lists 47 functions) \u003e Which of those haven't been invoked in 90 days? (agent filters to 12 functions) \u003e Delete the ones in the dev environment (agent identifies 5 functions and asks for confirmation) Use Natural Phrasing You donâ€™t need special syntax. These all work:\nâ€œList EC2 instancesâ€ â€œShow me the EC2 instancesâ€ â€œWhat EC2 instances do I have?â€ â€œI need to see all EC2 instancesâ€ Understanding Agent Responses Response Format Agents format responses for readability:\n\u003e Check security group rules for public access ğŸ” Scanning security groups... Found 3 security groups with public access (0.0.0.0/0): âš ï¸ sg-abc123 (web-servers) Port 443 (HTTPS) - OK, expected for web servers Port 22 (SSH) - âš ï¸ Consider restricting to bastion IP âš ï¸ sg-def456 (database) Port 5432 (PostgreSQL) - ğŸš¨ HIGH RISK: Database exposed to internet âœ… sg-ghi789 (internal-services) No public access rules Confidence Indicators Agents indicate when theyâ€™re uncertain:\n\u003e How much will my bill be next month? Based on current usage patterns, I estimate $4,200-$4,800. Note: This estimate assumes: - Current instance counts remain stable - No significant data transfer changes - Reserved instances continue at current rates For more accurate forecasting, consider connecting AWS Cost Explorer. Confirmation for Destructive Actions Agents always confirm before making changes:\n\u003e Delete all unused EBS volumes Found 8 unused EBS volumes (not attached to any instance): â€¢ vol-abc123 - 500GB - us-east-1a - $50/month â€¢ vol-def456 - 100GB - us-east-1b - $10/month ... Total monthly savings: $180 âš ï¸ This action cannot be undone. Delete these 8 volumes? [y/N] Agent Memory and Context Session Context Within a session, agents remember the conversation:\n\u003e Show me RDS instances (lists 5 instances) \u003e Which one has the highest CPU? (understands \"which one\" refers to the RDS instances) Persistent Context Agents also learn about your infrastructure over time:\nCommon naming patterns Typical resource configurations Your organizationâ€™s terminology Clearing Context Reset the current session:\nc2g chat my-agent --new-session Advanced Agent Features Multi-Step Operations Agents can execute complex workflows:\n\u003e Migrate the database to a larger instance with minimal downtime Planning migration for rds-prod-db (db.r5.large â†’ db.r5.xlarge): 1. Create read replica with new instance size 2. Wait for replica sync (estimated: 2-4 hours) 3. Promote replica to primary 4. Update application connection strings 5. Terminate old instance Estimated downtime: \u003c 30 seconds during failover Estimated cost impact: +$200/month Proceed with this plan? [y/N] Scheduled Operations Schedule commands to run later:\n\u003e Every night at 2am, stop all dev instances and start them at 8am Created 2 scheduled tasks: â€¢ Stop dev instances - Daily at 2:00 AM UTC â€¢ Start dev instances - Daily at 8:00 AM UTC Estimated monthly savings: $340 Chained Commands Combine multiple operations:\n\u003e Find Lambda functions with errors \u003e 1% and increase their memory by 50% Found 3 functions with error rate \u003e 1%: â€¢ payment-processor: 2.3% errors, 512MB â†’ 768MB â€¢ email-sender: 1.5% errors, 256MB â†’ 384MB â€¢ report-generator: 4.1% errors, 1024MB â†’ 1536MB Apply these changes? [y/N] Troubleshooting Agent Not Responding Check agent status:\nc2g agent status my-agent Restart if needed:\nc2g agent restart my-agent Permission Errors If an agent canâ€™t perform an action, verify:\nCloud provider credentials are valid IAM permissions are sufficient Workspace policies allow the action c2g agent permissions my-agent Unclear Responses If an agent misunderstands, rephrase or provide more context:\n\u003e Show instances Agent: I found 45 EC2 instances and 12 RDS instances. Which would you like to see? \u003e Just EC2 instances in production Agent: Here are 23 EC2 instances in your production environment... ","categories":"","description":"How to interact with AI agents, issue commands, and interpret responses.\n","excerpt":"How to interact with AI agents, issue commands, and interpret â€¦","ref":"/en/docs/user-guide/agents/","tags":"","title":"Working with Agents"},{"body":"This guide gets you from zero to a running AI agent in just a few steps.\nPrerequisites Cloud2Gether CLI installed (installation guide) Authenticated with c2g auth login Cloud provider credentials ready Step 1: Connect a Cloud Provider Connect your AWS, Azure, or GCP account to Cloud2Gether.\nAWS Azure GCP ```bash # Create an IAM role for Cloud2Gether (recommended) c2g provider add aws --method role # Or use access keys c2g provider add aws \\ --access-key-id YOUR_ACCESS_KEY \\ --secret-access-key YOUR_SECRET_KEY \\ --region us-east-1 ``` ```bash # Use service principal authentication c2g provider add azure \\ --tenant-id YOUR_TENANT_ID \\ --client-id YOUR_CLIENT_ID \\ --client-secret YOUR_CLIENT_SECRET \\ --subscription-id YOUR_SUBSCRIPTION_ID ``` ```bash # Use service account key file c2g provider add gcp \\ --project-id YOUR_PROJECT_ID \\ --key-file /path/to/service-account.json ``` Verify the connection:\nc2g provider list Step 2: Deploy Your First Agent Deploy an infrastructure management agent:\nc2g agent deploy infrastructure \\ --name \"my-first-agent\" \\ --providers aws The agent will start and connect to your cloud provider. Check its status:\nc2g agent status my-first-agent Step 3: Issue Your First Command Now the fun part! Talk to your agent using natural language:\nc2g chat my-first-agent This opens an interactive session. Try these commands:\n\u003e List all EC2 instances in us-east-1 \u003e Show me resources that haven't been used in the last 30 days \u003e What's my current monthly spend estimate? Or run a single command:\nc2g run my-first-agent \"List all S3 buckets and their sizes\" Step 4: Automate a Task Create your first automation â€” letâ€™s set up cost optimization alerts:\nc2g run my-first-agent \"Set up a daily report of unused resources and email it to team@mycompany.com\" The agent will:\nAnalyze your infrastructure Create a scheduled task Configure email notifications Confirm the setup What Just Happened? Behind the scenes, the Cloud2Gether agent:\nConnected to your AWS account using the credentials you provided Scanned available resources and permissions Interpreted your natural language commands Executed API calls to gather information or make changes Reported results in human-readable format Example Workflows Here are some common tasks you can automate right away:\nInfrastructure Visibility c2g run my-first-agent \"Give me a summary of my infrastructure\" Cost Optimization c2g run my-first-agent \"Find resources I can safely delete to save money\" Security Audit c2g run my-first-agent \"Check for security groups with ports open to 0.0.0.0/0\" Deployment c2g run my-first-agent \"Deploy the latest version of my-app to production with zero downtime\" Next Steps Core Concepts â€” Understand how agents work User Guide â€” Deep dive into features AI Agents Reference â€” Explore all agent types ","categories":"","description":"Deploy your first AI agent and automate infrastructure in under 5 minutes.\n","excerpt":"Deploy your first AI agent and automate infrastructure in under 5 â€¦","ref":"/en/docs/getting-started/quickstart/","tags":"","title":"Quick Start"},{"body":"Security Model Cloud2Gether is designed with security as a foundational principle.\nData Protection Aspect Protection Data in transit TLS 1.3 encryption Data at rest AES-256 encryption Secrets Encrypted with customer-specific keys API keys Hashed, never stored in plain text Infrastructure Security Hosted on AWS with SOC 2 certified infrastructure Network isolation between customer workspaces Regular security assessments and penetration testing 24/7 security monitoring Agent Security Agents operate with:\nMinimal required permissions Encrypted credential storage All actions logged for audit Configurable policies for guardrails Audit Logs All actions in Cloud2Gether are logged for audit purposes.\nViewing Audit Logs Dashboard Go to Settings â†’ Audit Logs Filter by date, user, action, or resource Export logs as needed CLI c2g audit list --last 24h c2g audit list --user user@example.com --action delete c2g audit export --start 2024-01-01 --end 2024-01-31 --format csv API curl -X GET \"https://api.cloud2gether.com/v1/audit?start=2024-01-01\u0026end=2024-01-15\" \\ -H \"Authorization: Bearer $API_KEY\" Log Contents Each audit log entry includes:\n{ \"id\": \"audit_abc123\", \"timestamp\": \"2024-01-15T10:30:00Z\", \"user\": { \"id\": \"user_xyz\", \"email\": \"user@example.com\" }, \"action\": \"agent.command.run\", \"resource\": { \"type\": \"agent\", \"id\": \"agent_abc123\", \"name\": \"prod-infra\" }, \"details\": { \"command\": \"Stop all dev instances\", \"result\": \"success\", \"affected_resources\": 12 }, \"ip_address\": \"192.168.1.1\", \"user_agent\": \"c2g-cli/1.0.0\" } Log Retention Plan Retention Free 7 days Pro 90 days Enterprise 1 year+ (customizable) SIEM Integration Export logs to your SIEM:\n# siem-integration.yaml type: splunk config: endpoint: https://your-splunk.com:8088 token: ${SPLUNK_HEC_TOKEN} index: cloud2gether source: cloud2gether-audit Supported integrations:\nSplunk Datadog Sumo Logic Elastic AWS CloudWatch Custom webhooks Compliance Certifications Certification Status SOC 2 Type II Certified ISO 27001 Certified GDPR Compliant HIPAA Available (Enterprise) PCI-DSS Level 1 Compliant Compliance Reports Access compliance reports:\nGo to Settings â†’ Security â†’ Compliance Download SOC 2 report, penetration test results, etc. Request custom attestation letters Data Residency Choose where your data is stored:\nRegion Location US AWS us-east-1 (Virginia) EU AWS eu-west-1 (Ireland) APAC AWS ap-southeast-1 (Singapore) Enterprise customers can request additional regions.\nNetwork Security IP Allowlisting Restrict access to specific IP addresses:\nc2g security ip-allowlist add 203.0.113.0/24 --description \"Office network\" c2g security ip-allowlist add 198.51.100.1 --description \"VPN endpoint\" Private Networking For Enterprise customers:\nVPC peering AWS PrivateLink Azure Private Link GCP Private Service Connect Secrets Management How Secrets Are Stored Cloud provider credentials are encrypted with workspace-specific keys Keys are managed in AWS KMS or customer-provided KMS Secrets are never logged or exposed in API responses Bring Your Own Key (BYOK) Enterprise customers can use their own encryption keys:\nc2g security kms configure \\ --provider aws \\ --key-arn arn:aws:kms:us-east-1:123456789:key/abc-123 Credential Rotation Rotate provider credentials:\nc2g provider rotate aws Set up automatic rotation:\ncredential_rotation: enabled: true interval: 90d providers: [aws, azure, gcp] notification_channel: \"#security\" Security Headers API responses include security headers:\nStrict-Transport-Security: max-age=31536000; includeSubDomains X-Content-Type-Options: nosniff X-Frame-Options: DENY X-XSS-Protection: 1; mode=block Content-Security-Policy: default-src 'self' Vulnerability Reporting Report security vulnerabilities to security@cloud2gether.com.\nBug Bounty Program We offer rewards for responsible disclosure:\nSeverity Reward Critical $5,000 - $10,000 High $1,000 - $5,000 Medium $500 - $1,000 Low $100 - $500 Security Best Practices Enable MFA â€” Require multi-factor authentication for all users Use SSO â€” Integrate with your identity provider Rotate credentials â€” Set up automatic credential rotation Apply policies â€” Define guardrails for agent actions Review audit logs â€” Regularly review activity IP allowlisting â€” Restrict access to known networks Least privilege â€” Grant minimum necessary permissions Monitor alerts â€” Set up security alerting Incident Response If you suspect a security incident:\nContact security@cloud2gether.com immediately Provide details: what happened, when, affected resources Our security team will respond within 1 hour Weâ€™ll provide regular updates until resolution Incident History View past security notifications:\nGo to Settings â†’ Security â†’ Incidents View incident reports and remediations ","categories":"","description":"Configure security settings, understand our security model, and maintain compliance.\n","excerpt":"Configure security settings, understand our security model, and â€¦","ref":"/en/docs/admin/security/","tags":"","title":"Security \u0026 Compliance"},{"body":"The Security Agent continuously monitors your infrastructure for security issues and compliance violations.\nCapabilities Category Operations Configuration Audit Check for misconfigurations, open ports, public access Compliance CIS benchmarks, SOC 2, HIPAA, PCI-DSS checks Vulnerability Scanning Identify vulnerable images, outdated packages Access Analysis IAM review, permission analysis, unused credentials Network Security Security group analysis, flow log review Secrets Detection Find exposed credentials, API keys Deployment c2g agent deploy security \\ --name security-audit \\ --providers aws,azure,gcp Configuration name: security-audit type: security providers: - name: aws regions: all - name: azure subscriptions: all - name: gcp projects: all settings: # Scan frequency scan_interval: 1h # Compliance frameworks to check compliance_frameworks: - cis-aws-1.5 - cis-azure-1.4 - soc2 # Severity threshold for alerts alert_threshold: medium notifications: slack: \"#security-alerts\" pagerduty: security-team Security Scans On-Demand Scan \u003e Run a security scan on production Running comprehensive security scan... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Security Scan Report - Production â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ğŸš¨ Critical: 2 âš ï¸ High: 5 ğŸ“‹ Medium: 12 â„¹ï¸ Low: 23 CRITICAL FINDINGS: 1. S3 Bucket Publicly Accessible Resource: s3://company-backups Risk: Sensitive data exposed to internet Remediation: Remove public access block 2. Database Exposed to Internet Resource: rds:prod-mysql Risk: Database accessible from 0.0.0.0/0 Remediation: Restrict security group HIGH FINDINGS: 1. Root Account Has Access Keys Risk: Root credentials could be compromised Remediation: Delete root access keys, use IAM 2. MFA Not Enabled for IAM Users (3 users) Risk: Accounts vulnerable to password attacks Remediation: Require MFA for all users [Full report available: https://app.cloud2gether.com/reports/scan-abc123] Shall I remediate any of these issues? Compliance Check \u003e Check CIS AWS compliance Running CIS AWS Foundations Benchmark 1.5... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” CIS AWS Foundations Benchmark 1.5 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Overall Score: 78/100 Section 1: Identity and Access Management âœ“ 1.1 Avoid root account usage âœ“ 1.2 MFA enabled for root âœ— 1.3 Unused credentials disabled âœ— 1.4 Access keys rotated in 90 days âœ“ 1.5 Password policy requirements ... Section 2: Logging âœ“ 2.1 CloudTrail enabled âœ“ 2.2 Log file validation âœ— 2.3 CloudTrail logs encrypted ... Section 3: Monitoring âœ— 3.1 Unauthorized API calls alarm âœ— 3.2 Console sign-in without MFA alarm ... Failed Checks: 22 Passed Checks: 78 Not Applicable: 5 [Export full report as PDF?] IAM Analysis \u003e Analyze IAM permissions for over-privileged roles Analyzing 47 IAM roles... Over-Privileged Roles Found: ğŸš¨ lambda-execution-role Issue: Has AdministratorAccess policy Attached to: 12 Lambda functions Recommendation: Create least-privilege policy âš ï¸ ecs-task-role Issue: Has s3:* permissions Used by: api-service Recommendation: Restrict to specific buckets âš ï¸ developer-role Issue: Can modify production resources Members: 15 users Recommendation: Separate prod/dev permissions Unused Roles (no activity in 90 days): 8 Roles with unused permissions: 23 Generate remediation plan? [y/N] Network Security \u003e Show all resources exposed to the internet Scanning network configurations... Publicly Accessible Resources: EXPECTED (Web-Facing): âœ“ alb-prod-web (443, 80) - Load balancer for web app âœ“ alb-prod-api (443) - API gateway NEEDS REVIEW: âš ï¸ i-abc123 (22) - SSH exposed, should use bastion âš ï¸ rds-staging (3306) - MySQL exposed for testing CRITICAL - SHOULD NOT BE PUBLIC: ğŸš¨ rds-production (5432) - Production database! ğŸš¨ elasticsearch-prod (9200) - Elasticsearch cluster Remediate critical issues immediately? [y/N] Continuous Monitoring Security Rules Configure ongoing monitoring:\nmonitoring: rules: - name: public-s3-bucket condition: s3_bucket.public_access == true severity: critical action: alert_and_remediate - name: security-group-change condition: security_group.modified == true severity: high action: alert - name: iam-policy-change condition: iam_policy.modified == true severity: medium action: log - name: unused-access-keys condition: access_key.last_used \u003e 90d severity: medium action: alert Alert Responses The agent can take automated actions:\nremediation: - issue: public_s3_bucket action: block_public_access require_approval: false - issue: open_security_group_port action: remove_rule require_approval: true - issue: exposed_credentials action: rotate_and_notify require_approval: false Vulnerability Scanning Container Image Scanning \u003e Scan container images in ECR for vulnerabilities Scanning 45 images in ECR... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Container Vulnerability Report â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Critical Vulnerabilities: 3 images affected api-service:v2.3.1 â€¢ CVE-2024-1234: Remote code execution in libcurl â€¢ CVE-2024-5678: SQL injection in mysql-client Recommendation: Rebuild with updated base image worker:v1.8.0 â€¢ CVE-2024-9012: Privilege escalation in sudo Recommendation: Update base image to alpine:3.19 web-frontend:v4.1.2 â€¢ CVE-2024-3456: XSS vulnerability in lodash Recommendation: Update lodash to 4.17.21 Images with no critical vulnerabilities: 42 Last scan: 2 hours ago Auto-rebuild affected images? [y/N] Dependency Scanning \u003e Check for vulnerable dependencies in our repositories Scanning connected repositories... Vulnerable Dependencies Found: myorg/backend (23 vulnerabilities) â€¢ Critical: 2 â€¢ High: 5 â€¢ Medium: 16 Critical: - log4j 2.14.0 â†’ 2.21.0 (CVE-2021-44228) - jackson-databind 2.9.8 â†’ 2.16.0 (CVE-2020-36518) myorg/frontend (8 vulnerabilities) â€¢ High: 3 â€¢ Medium: 5 High: - axios 0.21.1 â†’ 1.6.0 (CVE-2023-45857) Create pull requests to update dependencies? [y/N] Secrets Detection \u003e Scan for exposed secrets in S3 and repositories Scanning for secrets... âš ï¸ Potential Secrets Found: S3 Buckets: s3://config-files/app.env â€¢ AWS_SECRET_ACCESS_KEY detected â€¢ DATABASE_PASSWORD detected Action: File should be encrypted or moved to Secrets Manager s3://logs-archive/debug-2024-01.log â€¢ API key pattern detected (line 4521) Action: Rotate key, remove from logs Repositories: myorg/backend/.env.example â€¢ Contains actual credentials (not placeholders) Action: Replace with placeholders, rotate credentials Rotate detected credentials? [y/N] Reporting Generate Security Report \u003e Generate monthly security report for leadership Generating Executive Security Report... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Monthly Security Report - January 2024 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Security Posture Score: 82/100 (â†‘5 from last month) Key Metrics: â€¢ Critical vulnerabilities: 3 (â†“2) â€¢ High-risk configurations: 8 (â†“4) â€¢ Compliance score: 89% (â†‘3%) â€¢ Mean time to remediate: 4.2 hours (â†“1.3 hours) Top Achievements: âœ“ Eliminated all publicly accessible databases âœ“ Enabled MFA for all admin accounts âœ“ Reduced IAM over-privileging by 40% Remaining Priorities: 1. Complete encryption at rest for all S3 buckets 2. Implement VPC flow log monitoring 3. Update legacy container base images [PDF report generated: security-report-jan-2024.pdf] Permissions Required The Security Agent needs read access to audit configurations:\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"iam:Get*\", \"iam:List*\", \"s3:GetBucket*\", \"s3:ListBucket*\", \"ec2:Describe*\", \"rds:Describe*\", \"cloudtrail:Describe*\", \"config:Describe*\", \"inspector:*\", \"securityhub:*\" ], \"Resource\": \"*\" } ] } For remediation capabilities, additional write permissions are needed.\n","categories":"","description":"Audit configurations, detect vulnerabilities, and ensure compliance.\n","excerpt":"Audit configurations, detect vulnerabilities, and ensure compliance.\n","ref":"/en/docs/ai-agents/security/","tags":"","title":"Security Agent"},{"body":"This guide covers the day-to-day usage of Cloud2Gether, from working with agents to setting up automations.\nTopics Working with Agents Learn how to interact with AI agents, issue commands, and understand their responses. [Read more â†’](agents/) Workflows \u0026 Automation Create automated workflows that run on schedules or in response to events. [Read more â†’](workflows/) Dashboard Navigate the Cloud2Gether dashboard and understand your infrastructure at a glance. [Read more â†’](dashboard/) Integrations Connect Cloud2Gether to Slack, Teams, PagerDuty, and other tools your team uses. [Read more â†’](integrations/) Best Practices Tips and patterns for getting the most out of Cloud2Gether. [Read more â†’](best-practices/) ","categories":"","description":"Learn how to use Cloud2Gether effectively for your DevOps workflows.\n","excerpt":"Learn how to use Cloud2Gether effectively for your DevOps workflows.\n","ref":"/en/docs/user-guide/","tags":"","title":"User Guide"},{"body":"Cloud2Gether workflows let you automate repetitive tasks and create event-driven automations.\nWorkflow Types Scheduled Workflows Run tasks on a recurring schedule:\n# daily-cleanup.yaml name: Daily Cleanup schedule: \"0 2 * * *\" # 2 AM daily agent: infrastructure steps: - command: \"Stop all EC2 instances tagged Environment=dev\" - command: \"Delete EBS snapshots older than 30 days\" - command: \"Remove unused Elastic IPs\" Event-Driven Workflows Respond to infrastructure events:\n# high-cpu-response.yaml name: High CPU Response trigger: type: cloudwatch metric: CPUUtilization threshold: 90 duration: 5m agent: infrastructure steps: - command: \"Analyze why {{ .resource }} has high CPU\" - command: \"If safe, scale horizontally by adding 2 instances\" - notify: channel: \"#ops-alerts\" message: \"High CPU detected on {{ .resource }}\" Manual Workflows Pre-defined runbooks you trigger manually:\n# deploy-production.yaml name: Production Deployment trigger: manual agent: deployment inputs: - name: version type: string required: true - name: rollback_on_failure type: boolean default: true steps: - command: \"Deploy {{ .inputs.version }} to production\" - wait: 5m - command: \"Verify deployment health\" - on_failure: - command: \"Rollback to previous version\" - notify: channel: \"#deployments\" message: \"Deployment failed, rolled back\" Creating Workflows Using the CLI Create a workflow from a YAML file:\nc2g workflow create -f daily-cleanup.yaml Or create interactively:\nc2g workflow create --interactive Using the Dashboard Navigate to Workflows in the sidebar Click Create Workflow Use the visual editor or YAML mode Using Natural Language Ask an agent to create a workflow:\n\u003e Create a workflow that runs every Monday at 9am and sends me a cost report Created workflow: weekly-cost-report Schedule: Every Monday at 9:00 AM Agent: cost Actions: 1. Generate cost report for the past week 2. Compare to previous week 3. Send email to you@example.com Workflow is now active. Workflow Configuration Schedule Syntax Cloud2Gether uses standard cron expressions:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ minute (0-59) â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hour (0-23) â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ day of month (1-31) â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ month (1-12) â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ day of week (0-6, Sunday=0) â”‚ â”‚ â”‚ â”‚ â”‚ * * * * * Common examples:\nSchedule Cron Expression Every hour 0 * * * * Daily at midnight 0 0 * * * Weekdays at 9 AM 0 9 * * 1-5 First of month 0 0 1 * * Workflow Steps Workflows support various step types:\nsteps: # Run an agent command - command: \"List all stopped instances\" # Wait for a duration - wait: 5m # Run steps in parallel - parallel: - command: \"Check us-east-1\" - command: \"Check us-west-2\" - command: \"Check eu-west-1\" # Conditional execution - if: \"{{ .previous.result.count \u003e 0 }}\" then: - command: \"Send alert\" else: - command: \"Log all clear\" # Error handling - command: \"Risky operation\" on_failure: - notify: channel: \"#alerts\" message: \"Operation failed: {{ .error }}\" Notifications Send notifications to various channels:\n- notify: channel: \"#ops\" # Slack channel message: \"Task completed\" - notify: type: email to: [\"team@example.com\"] subject: \"Weekly Report\" body: \"{{ .report }}\" - notify: type: pagerduty severity: high message: \"Critical issue detected\" Managing Workflows List Workflows c2g workflow list Output:\nNAME STATUS SCHEDULE LAST RUN daily-cleanup active 0 2 * * * 2h ago weekly-cost-report active 0 9 * * 1 5d ago deploy-production active manual 1d ago security-scan paused 0 0 * * 0 7d ago View Workflow Details c2g workflow describe daily-cleanup Pause/Resume Workflows c2g workflow pause daily-cleanup c2g workflow resume daily-cleanup Trigger Manual Workflows c2g workflow run deploy-production --input version=v2.3.1 View Execution History c2g workflow history daily-cleanup Output:\nRUN ID STARTED DURATION STATUS run-abc123 2024-01-15 02:00:00 3m 24s success run-def456 2024-01-14 02:00:00 2m 58s success run-ghi789 2024-01-13 02:00:00 8m 12s failed View Execution Details c2g workflow logs run-abc123 Workflow Examples Cost Optimization Workflow name: Weekly Cost Optimization schedule: \"0 9 * * 1\" # Monday 9 AM agent: cost steps: - command: \"Find all unused resources\" output: unused - command: \"Calculate potential savings from {{ .unused }}\" output: savings - if: \"{{ .savings.total \u003e 100 }}\" then: - notify: channel: \"#cost-alerts\" message: | ğŸ’° Weekly Cost Optimization Report Found ${{ .savings.total }}/month in potential savings: {{ range .unused }} â€¢ {{ .type }}: {{ .name }} - ${{ .monthly_cost }} {{ end }} Incident Response Workflow name: Database Incident Response trigger: type: cloudwatch alarm: database-connection-errors agent: infrastructure steps: - notify: type: pagerduty severity: high message: \"Database connection errors detected\" - command: \"Check database {{ .resource }} health\" output: health - command: \"List recent changes to database configuration\" output: changes - command: \"Gather relevant logs from the last 30 minutes\" output: logs - notify: channel: \"#incidents\" message: | ğŸš¨ Database Incident Resource: {{ .resource }} Health: {{ .health }} Recent changes: {{ .changes }} Runbook: https://wiki.example.com/db-incident Deployment Pipeline name: Production Deployment trigger: manual inputs: - name: service type: string required: true - name: version type: string required: true agent: deployment steps: - command: \"Deploy {{ .inputs.service }}:{{ .inputs.version }} to staging\" - wait: 2m reason: \"Waiting for staging deployment to stabilize\" - command: \"Run integration tests against staging\" output: tests - if: \"{{ .tests.passed }}\" then: - command: \"Deploy {{ .inputs.service }}:{{ .inputs.version }} to production with blue-green strategy\" - notify: channel: \"#deployments\" message: \"âœ… Deployed {{ .inputs.service }}:{{ .inputs.version }} to production\" else: - notify: channel: \"#deployments\" message: \"âŒ Deployment blocked: integration tests failed\" - command: \"Rollback staging to previous version\" Best Practices Start simple â€” Begin with basic workflows and add complexity as needed Add notifications â€” Always notify on failures Use dry runs â€” Test workflows with --dry-run before activating Version control â€” Store workflow YAML files in git Document purpose â€” Add descriptions to explain why workflows exist ","categories":"","description":"Create automated workflows that run on schedules or respond to events.\n","excerpt":"Create automated workflows that run on schedules or respond to events. â€¦","ref":"/en/docs/user-guide/workflows/","tags":"","title":"Workflows \u0026 Automation"},{"body":"AI agents are the core of Cloud2Gether. Theyâ€™re autonomous workers that understand your infrastructure and can execute complex operations on your behalf.\nHow Agents Work â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ Cloud2Gether Agent â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚ Natural â”‚ â”‚ Context â”‚ â”‚ Action â”‚ â”‚ â”‚ â”‚ Language â”‚â”€â”€â”‚ Engine â”‚â”€â”€â”‚ Executor â”‚ â”‚ â”‚ â”‚ Processor â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â–¼ â–¼ â–¼ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚ Understands â”‚ â”‚ Remembers â”‚ â”‚ Executes â”‚ â”‚ â”‚ â”‚ your intent â”‚ â”‚ your infra â”‚ â”‚ safely â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â–¼ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ Cloud Providers â”‚ â”‚ AWS â”‚ Azure â”‚ GCP â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Key Capabilities Capability Description Natural Language Understanding Interpret commands in plain English Infrastructure Awareness Maintain real-time knowledge of your resources Safe Execution Confirm destructive actions, respect policies Continuous Learning Improve recommendations based on patterns Multi-Cloud Support Work across AWS, Azure, GCP, and Kubernetes Agent Types Cloud2Gether provides specialized agents for different domains:\nInfrastructure Agent Manage compute, storage, and networking resources across all your cloud providers. [Learn more â†’](infrastructure/) Security Agent Audit configurations, detect vulnerabilities, and ensure compliance. [Learn more â†’](security/) Cost Agent Optimize spending, identify waste, and manage budgets. [Learn more â†’](cost/) Deployment Agent Handle CI/CD, releases, rollbacks, and deployment strategies. [Learn more â†’](deployment/) Monitoring Agent Observe systems, respond to incidents, and maintain reliability. [Learn more â†’](monitoring/) Custom Agents Build your own agents for specialized use cases. [Learn more â†’](custom/) Deploying Agents Quick Deploy Deploy a pre-configured agent:\nc2g agent deploy infrastructure \\ --name prod-infra \\ --providers aws,gcp Custom Configuration Deploy with a configuration file:\n# agent-config.yaml name: prod-infra type: infrastructure providers: - name: aws regions: [us-east-1, us-west-2] - name: gcp projects: [my-project-id] policies: - production-safety notifications: slack: \"#infrastructure\" c2g agent deploy -f agent-config.yaml Agent Lifecycle States State Description deploying Agent is starting up running Agent is active and ready paused Agent is stopped but preserves state error Agent encountered a problem terminated Agent has been deleted Management Commands # List all agents c2g agent list # Check agent status c2g agent status my-agent # View agent logs c2g agent logs my-agent # Pause an agent c2g agent pause my-agent # Resume an agent c2g agent resume my-agent # Restart an agent c2g agent restart my-agent # Delete an agent c2g agent delete my-agent Agent Policies Policies define what agents can and cannot do.\nPolicy Structure name: production-safety description: Safety rules for production agents rules: # Require approval for deletes - action: delete resources: [\"*\"] require: approval approvers: [\"admin\", \"ops-team\"] # Block certain operations entirely - action: terminate resources: [\"database/*\"] deny: true message: \"Database termination requires manual intervention\" # Allow all read operations - action: query resources: [\"*\"] allow: true # Rate limit modifications - action: modify resources: [\"*\"] rate_limit: 10/hour Applying Policies # Create a policy c2g policy create -f production-safety.yaml # Apply to an agent c2g agent update my-agent --policies production-safety # List agent policies c2g agent policies my-agent Agent Communication Interactive Chat c2g chat my-agent Single Commands c2g run my-agent \"Your command here\" Programmatic Access from cloud2gether import Client client = Client() agent = client.agent(\"my-agent\") # Run a command result = agent.run(\"List all EC2 instances\") print(result.text) # Stream responses for chunk in agent.stream(\"Analyze my infrastructure\"): print(chunk, end=\"\") Best Practices One agent per concern â€” Deploy specialized agents for infrastructure, security, cost, etc. Apply policies first â€” Configure guardrails before giving agents access Start with read-only â€” Begin with query permissions, add write access gradually Monitor activity â€” Review agent logs regularly Use staging first â€” Test agent configurations in non-production environments ","categories":"","description":"Understand how Cloud2Gether's AI agents work and explore the different agent types available.\n","excerpt":"Understand how Cloud2Gether's AI agents work and explore the different â€¦","ref":"/en/docs/ai-agents/","tags":"","title":"AI Agents"},{"body":"What is Agentic DevOps? Traditional DevOps requires engineers to write scripts, configure tools, and manually orchestrate workflows. Agentic DevOps takes a different approach: AI agents that understand your intent and figure out how to achieve it.\nInstead of writing:\n# Traditional: You write the how - name: Deploy application hosts: production tasks: - docker_image: ... - docker_container: ... You say:\nDeploy my application to production with zero downtime The agent handles the implementation details.\nKey Concepts Agents Agents are AI-powered workers that manage your infrastructure. Each agent:\nHas specific capabilities (infrastructure, security, cost, etc.) Maintains context about your environment Can execute actions on your behalf Learns from your infrastructure patterns Agents are not just chatbots â€” theyâ€™re autonomous workers that can:\nMonitor your infrastructure continuously Take proactive actions based on policies Alert you to issues before they become problems Execute complex multi-step workflows Workspaces A Workspace is an isolated environment containing:\nConnected cloud providers Deployed agents Configuration and policies Team members and permissions Most organizations use one workspace per environment (dev, staging, production) or per team.\nProviders Providers are the cloud platforms Cloud2Gether connects to:\nAWS â€” EC2, S3, Lambda, RDS, EKS, and 200+ services Azure â€” VMs, Storage, Functions, AKS, and more GCP â€” Compute Engine, Cloud Storage, Cloud Functions, GKE Kubernetes â€” Any cluster, managed or self-hosted Custom â€” Connect any API via provider plugins Actions Actions are operations agents can perform:\nAction Type Examples Query List resources, check status, analyze costs Modify Create, update, delete resources Monitor Watch for changes, alert on thresholds Automate Schedule tasks, create workflows Actions have built-in safety:\nDestructive operations require confirmation All actions are logged and auditable Policies can restrict what agents can do Policies Policies define guardrails for agent behavior:\n# Example policy name: production-safety rules: - action: delete resources: [\"*\"] require: approval - action: modify resources: [\"database/*\"] require: approval - action: query resources: [\"*\"] allow: true Policies ensure agents operate within boundaries you define.\nHow Agents Work â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ You â”‚â”€â”€â”€â”€â–¶â”‚ Agent â”‚â”€â”€â”€â”€â–¶â”‚ Cloud â”‚ â”‚ (Intent) â”‚ â”‚ (AI) â”‚ â”‚ Provider â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â–² â”‚ â”‚ â”‚ â–¼ â–¼ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Response â”‚â—€â”€â”€â”€â”€â”‚ Results â”‚ â”‚ (Human) â”‚ â”‚ (Data) â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ You express intent â€” Natural language describing what you want Agent interprets â€” AI understands the goal and plans steps Agent executes â€” API calls to your cloud providers Results returned â€” Human-readable summary of what happened Agent Types Cloud2Gether provides specialized agents for different tasks:\nAgent Type Purpose Infrastructure Manage compute, storage, networking Security Audit, compliance, vulnerability scanning Cost Optimization, budgeting, waste detection Deployment CI/CD, releases, rollbacks Monitoring Observability, alerting, incident response Learn more in the AI Agents documentation.\nSecurity Model Cloud2Gether is designed with security first:\nLeast privilege â€” Agents only access what they need Audit logging â€” Every action is recorded Encryption â€” All data encrypted in transit and at rest No data storage â€” We donâ€™t store your infrastructure data SOC 2 compliant â€” Enterprise-grade security practices See Security \u0026 Compliance for details.\nNext Steps Now that you understand the concepts:\nDeploy more agents Configure policies Set up team access ","categories":"","description":"Understand the fundamental concepts behind Cloud2Gether's agentic DevOps platform.\n","excerpt":"Understand the fundamental concepts behind Cloud2Gether's agentic â€¦","ref":"/en/docs/getting-started/concepts/","tags":"","title":"Core Concepts"},{"body":"The Cost Agent helps you understand and optimize your cloud spending across all providers.\nCapabilities Category Operations Cost Analysis Break down spending by service, team, project Waste Detection Find unused resources, oversized instances Right-Sizing Recommend optimal instance sizes Reserved Capacity RI/Savings Plan recommendations Budget Management Set budgets, alert on thresholds Forecasting Predict future spending Deployment c2g agent deploy cost \\ --name cost-optimizer \\ --providers aws,azure,gcp Configuration name: cost-optimizer type: cost providers: - name: aws cost_explorer: true billing_account: true - name: azure cost_management: true - name: gcp billing_export: true settings: # Currency for reports currency: USD # Alert when spending exceeds forecast by this % forecast_alert_threshold: 20 # Consider resources idle after this period idle_threshold: 7d notifications: slack: \"#cost-alerts\" email: [\"finance@company.com\"] Cost Analysis Current Spending \u003e What's our cloud spend this month? â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Cloud Spending - January 2024 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Month to Date: $47,234 Forecasted Total: $68,500 Budget: $75,000 (91% of budget) By Provider: AWS: $38,450 (81%) Azure: $6,284 (13%) GCP: $2,500 (6%) Top Services (AWS): 1. EC2: $18,200 (47%) 2. RDS: $8,450 (22%) 3. S3: $4,200 (11%) 4. Lambda: $2,100 (5%) 5. Other: $5,500 (15%) Compared to Last Month: â€¢ Total: â†‘12% (+$7,300) â€¢ EC2: â†‘18% (new instances for product launch) â€¢ RDS: â†“5% (reserved instance savings) Cost by Team \u003e Break down costs by team Cost Allocation by Team (January): Engineering: $32,450 (69%) â”œâ”€ Backend: $18,200 â”œâ”€ Frontend: $8,100 â””â”€ ML: $6,150 Data: $8,900 (19%) â”œâ”€ Analytics: $5,400 â””â”€ Data Eng: $3,500 DevOps: $4,200 (9%) Untagged: $1,684 (3%) âš ï¸ 23 resources missing Team tag Would you like me to: a) Show details for a specific team b) List untagged resources c) Generate cost allocation report Cost Trends \u003e Show me our spending trend over the last 6 months â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6-Month Spending Trend â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Aug 2023: $52,100 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Sep 2023: $54,800 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Oct 2023: $51,200 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Nov 2023: $58,900 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Dec 2023: $61,200 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Jan 2024: $68,500* â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ *forecast Trend: +31% over 6 months Average monthly growth: 5.2% Key Drivers: â€¢ Nov: ML training jobs (+$4,800) â€¢ Dec: Holiday traffic scaling (+$2,300) â€¢ Jan: New product launch (+$7,300) Waste Detection Find Unused Resources \u003e Find resources we're paying for but not using Scanning for unused resources... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Unused Resources Report â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Total Monthly Waste: $2,847 EC2 Instances (idle \u003e7 days): $1,240/month â€¢ i-abc123 (test-server-old) - 0% CPU for 45 days â€¢ i-def456 (dev-experiment) - 2% CPU for 30 days â€¢ i-ghi789 (backup-manual) - stopped for 60 days EBS Volumes (unattached): $456/month â€¢ vol-abc123 - 500 GB, unattached 90 days â€¢ vol-def456 - 200 GB, unattached 60 days â€¢ vol-ghi789 - 100 GB, unattached 45 days Elastic IPs (unused): $32/month â€¢ eip-abc123 - not attached â€¢ eip-def456 - not attached Load Balancers (no traffic): $180/month â€¢ alb-staging-old - 0 requests for 30 days Snapshots (old): $340/month â€¢ 145 snapshots older than 90 days RDS (oversized): $599/month â€¢ db.r5.large running at 8% CPU - consider db.r5.medium Delete these unused resources? [y/N] Right-Sizing \u003e Which instances are over-provisioned? Analyzing instance utilization... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Right-Sizing Recommendations â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Potential Monthly Savings: $3,450 COMPUTE: web-server-1 (i-abc123) Current: c5.2xlarge (8 vCPU, 16 GB) - $248/month Usage: Avg 12% CPU, Max 35% CPU Recommended: c5.xlarge (4 vCPU, 8 GB) - $124/month Savings: $124/month api-server-prod (i-def456) Current: m5.4xlarge (16 vCPU, 64 GB) - $614/month Usage: Avg 8% CPU, 15% memory Recommended: m5.xlarge (4 vCPU, 16 GB) - $154/month Savings: $460/month DATABASE: analytics-db (db.r5.2xlarge) Current: $576/month Usage: Avg 15% CPU, 20% memory Recommended: db.r5.large - $288/month Savings: $288/month Apply these recommendations? [y/N] Reserved Capacity RI Recommendations \u003e Should we buy reserved instances? Analyzing usage patterns for RI recommendations... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Reserved Instance Recommendations â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Annual Savings Potential: $18,400 RECOMMENDED PURCHASES: 1. EC2 Reserved Instances â€¢ 5x m5.xlarge (1-year, no upfront) Current: $5,472/year With RI: $3,456/year Savings: $2,016/year (37%) â€¢ 3x c5.2xlarge (1-year, partial upfront) Current: $8,928/year With RI: $5,357/year Savings: $3,571/year (40%) 2. RDS Reserved Instances â€¢ 2x db.r5.large (1-year, no upfront) Current: $5,184/year With RI: $3,276/year Savings: $1,908/year (37%) 3. Savings Plans (Alternative) â€¢ Compute Savings Plan $1,000/month commitment Covers: 75% of compute spending Savings: $10,800/year (30%) Show detailed comparison? [y/N] Budget Management Set Budgets \u003e Set a monthly budget of $70,000 with alerts Created budget: monthly-cloud-spend â€¢ Amount: $70,000/month â€¢ Alert at 50%: Notify #cost-alerts â€¢ Alert at 80%: Notify #cost-alerts + finance@company.com â€¢ Alert at 100%: Notify + page oncall Budget tracking is now active. Current spending: $47,234 (67% of budget) Budget Status \u003e How are we tracking against budgets? â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Budget Status - January 2024 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Overall: $47,234 / $70,000 (67%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 67% Status: On track âœ“ By Team: Engineering: $32,450 / $45,000 (72%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 72% Status: On track âœ“ Data: $8,900 / $12,000 (74%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 74% Status: On track âœ“ ML Training: $6,150 / $8,000 (77%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ 77% Status: âš ï¸ Above pace - forecast $9,200 DevOps: $4,200 / $5,000 (84%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 84% Status: âš ï¸ Needs attention Forecasting \u003e Forecast our spending for next quarter Analyzing historical patterns... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Q1 2024 Spending Forecast â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Forecast: $195,000 - $215,000 Monthly Breakdown: January: $68,500 (actual to date) February: $65,000 - $70,000 March: $62,000 - $75,000 Assumptions: â€¢ Normal seasonal patterns â€¢ No major new deployments â€¢ Current growth rate continues Factors That Could Change This: â†‘ Product launch in Feb (+$8,000-12,000) â†“ RI purchases (âˆ’$2,400) â†“ Waste cleanup (âˆ’$2,800) Best Case (with optimizations): $185,000 Expected: $205,000 Worst Case (with growth): $225,000 Cost Optimization Workflows Weekly Cost Report name: Weekly Cost Report schedule: \"0 9 * * 1\" # Monday 9 AM agent: cost-optimizer steps: - command: \"Generate weekly cost summary\" output: summary - command: \"Find new unused resources since last week\" output: waste - command: \"Check for cost anomalies\" output: anomalies - notify: channel: \"#cost-reports\" message: | ğŸ“Š Weekly Cloud Cost Report Spending: ${{ .summary.weekly_spend }} vs Last Week: {{ .summary.change }} New Waste Found: ${{ .waste.total }}/month Anomalies: {{ len .anomalies }} [View Full Report]({{ .summary.report_url }}) Cost Anomaly Alert name: Cost Anomaly Detection schedule: \"0 */4 * * *\" # Every 4 hours agent: cost-optimizer steps: - command: \"Check for spending anomalies in the last 4 hours\" output: anomalies - if: \"{{ len .anomalies \u003e 0 }}\" then: - notify: channel: \"#cost-alerts\" message: | ğŸš¨ Cost Anomaly Detected {{ range .anomalies }} â€¢ {{ .service }}: {{ .description }} Expected: ${{ .expected }} Actual: ${{ .actual }} {{ end }} Permissions Required { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ce:*\", \"cur:*\", \"aws-portal:View*\", \"budgets:*\", \"pricing:GetProducts\", \"ec2:Describe*\", \"rds:Describe*\", \"s3:GetBucket*\" ], \"Resource\": \"*\" } ] } ","categories":"","description":"Optimize cloud spending, identify waste, and manage budgets.\n","excerpt":"Optimize cloud spending, identify waste, and manage budgets.\n","ref":"/en/docs/ai-agents/cost/","tags":"","title":"Cost Agent"},{"body":"The Cloud2Gether dashboard at app.cloud2gether.com provides a visual interface for managing your infrastructure and agents.\nOverview When you log in, youâ€™ll see the main dashboard with key metrics:\nActive Agents â€” Number of agents running and their status Infrastructure Summary â€” Resource counts across providers Cost Overview â€” Current month spending and trends Recent Activity â€” Latest agent actions and events Alerts â€” Active issues requiring attention Navigation The left sidebar provides access to main sections:\nSection Description Dashboard Overview and quick stats Agents Manage AI agents Resources Browse infrastructure by provider Workflows Create and manage automations Activity View audit logs and history Costs Cost analytics and optimization Settings Workspace and account settings Agents View The Agents section shows all deployed agents:\nAgent List Each agent card displays:\nStatus â€” Running, stopped, or error Type â€” Infrastructure, security, cost, etc. Connected Providers â€” Which clouds it can access Last Activity â€” Most recent action Agent Details Click an agent to see:\nChat Interface â€” Interactive conversation Activity Log â€” Recent commands and results Metrics â€” Usage statistics Configuration â€” Settings and policies Agent Actions From the agent detail page:\nChat â€” Open interactive session Restart â€” Restart the agent Stop/Start â€” Control agent lifecycle Configure â€” Update settings Delete â€” Remove the agent Resources View Browse your infrastructure organized by provider and service:\nResource Browser Navigate through:\nAWS â”œâ”€â”€ EC2 â”‚ â”œâ”€â”€ Instances (24) â”‚ â”œâ”€â”€ Security Groups (18) â”‚ â””â”€â”€ Volumes (45) â”œâ”€â”€ S3 â”‚ â””â”€â”€ Buckets (12) â”œâ”€â”€ RDS â”‚ â””â”€â”€ Instances (5) â””â”€â”€ ... Resource Details Click any resource to see:\nProperties â€” Configuration and metadata Relationships â€” Connected resources Costs â€” Associated spending Activity â€” Recent changes Actions â€” What you can do Quick Actions Common actions available from resource views:\nStart/Stop instances Modify configurations View logs Open in cloud console Workflows View Manage your automated workflows:\nWorkflow List View all workflows with:\nStatus (active, paused, error) Schedule or trigger type Last execution result Next scheduled run Workflow Editor Create or edit workflows with:\nVisual Editor â€” Drag-and-drop step builder YAML Mode â€” Direct YAML editing Test Mode â€” Dry run without execution Execution History View past runs with:\nStart time and duration Success/failure status Step-by-step logs Output and results Cost View Analyze and optimize spending:\nCost Dashboard Current Month â€” Spending to date vs. forecast Trends â€” Month-over-month comparison By Service â€” Breakdown by cloud service By Tag â€” Breakdown by your tags (team, project, etc.) Optimization Recommendations AI-generated suggestions:\nUnused resources to delete Right-sizing opportunities Reserved instance recommendations Savings plan opportunities Budgets \u0026 Alerts Set up:\nMonthly budget thresholds Cost anomaly detection Alert notifications Activity \u0026 Audit View all actions and changes:\nActivity Feed Real-time stream of:\nAgent commands and responses Infrastructure changes User actions System events Audit Log Searchable history with:\nTimestamp User or agent Action type Affected resources Result Filters Filter by:\nDate range Agent User Action type Resource Settings Configure your workspace:\nWorkspace Settings General â€” Name, description Providers â€” Cloud connections Policies â€” Agent guardrails Notifications â€” Alert channels User Management Members â€” Add/remove users Roles â€” Define permissions Invitations â€” Pending invites SSO â€” Single sign-on configuration API \u0026 Integrations API Keys â€” Generate and manage keys Webhooks â€” Outgoing event hooks Integrations â€” Slack, Teams, PagerDuty, etc. Keyboard Shortcuts Navigate quickly with keyboard:\nShortcut Action g then d Go to Dashboard g then a Go to Agents g then r Go to Resources g then w Go to Workflows / Open search ? Show all shortcuts c Open agent chat n New workflow Mobile Access The dashboard is responsive and works on mobile devices. For the best experience on mobile:\nUse the hamburger menu for navigation Swipe to access actions Use the mobile-optimized chat interface A dedicated mobile app is available:\niOS App Store Google Play Store ","categories":"","description":"Navigate the Cloud2Gether web dashboard and monitor your infrastructure.\n","excerpt":"Navigate the Cloud2Gether web dashboard and monitor your â€¦","ref":"/en/docs/user-guide/dashboard/","tags":"","title":"Dashboard"},{"body":"Policies define what agents can and cannot do in your infrastructure.\nOverview Policies are sets of rules that control:\nWhich actions agents can perform Which resources they can access Whether approval is required Rate limits and quotas Policy Structure name: production-safety description: Safety rules for production environment version: 1 rules: # Require approval for destructive actions - action: delete resources: [\"*\"] effect: require_approval approvers: [\"admin\", \"ops-team\"] # Block modifications to critical infrastructure - action: modify resources: [\"database/*\", \"network/*\"] effect: deny message: \"Critical infrastructure changes require manual intervention\" # Allow all read operations - action: query resources: [\"*\"] effect: allow # Rate limit modifications - action: modify resources: [\"compute/*\"] effect: allow rate_limit: \"10/hour\" Creating Policies Via Dashboard Go to Settings â†’ Policies Click Create Policy Use the visual editor or YAML mode Save and apply to agents Via CLI c2g policy create -f production-safety.yaml Via API curl -X POST https://api.cloud2gether.com/v1/policies \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d @production-safety.json Rule Components Actions Action Description query Read data, list resources modify Update existing resources create Create new resources delete Delete resources execute Run commands, scripts * All actions Resources Use patterns to match resources:\n# All resources resources: [\"*\"] # Specific resource types resources: [\"ec2/*\", \"rds/*\"] # Specific resources by tag resources: [\"tag:Environment=production\"] # Specific resources by name resources: [\"instance:web-server-*\"] # Multiple patterns resources: - \"ec2/i-abc*\" - \"rds/prod-*\" - \"s3/company-*\" Effects Effect Description allow Permit the action deny Block the action require_approval Require human approval audit Allow but log prominently Conditions Add conditions for dynamic control:\nrules: - action: delete resources: [\"*\"] effect: allow conditions: - type: tag key: Environment value: development - action: modify resources: [\"*\"] effect: require_approval conditions: - type: time business_hours_only: true - action: create resources: [\"ec2/*\"] effect: allow conditions: - type: instance_type values: [\"t3.*\", \"t2.*\"] message: \"Only t2/t3 instances allowed\" Approval Workflows Configuring Approvers rules: - action: delete resources: [\"production/*\"] effect: require_approval approvers: users: [\"admin@company.com\"] roles: [\"admin\"] teams: [\"ops-team\"] approval_count: 2 # Require 2 approvers timeout: 2h # Auto-reject after 2 hours Approval Channels Configure where approval requests are sent:\napproval_notifications: slack: channel: \"#approvals\" email: recipients: [\"ops@company.com\"] pagerduty: service: approvals Approving Requests Via Slack Click the Approve or Reject button in the notification.\nVia CLI c2g approval list c2g approval approve apr_abc123 --comment \"Approved for maintenance\" c2g approval reject apr_abc123 --reason \"Not authorized\" Via Dashboard Go to Activity â†’ Pending Approvals Review the request Click Approve or Reject Built-in Policies production-safety Recommended for production environments:\nname: production-safety rules: - action: delete resources: [\"*\"] effect: require_approval - action: modify resources: [\"database/*\", \"network/*\"] effect: require_approval - action: query resources: [\"*\"] effect: allow development-permissive For development environments:\nname: development-permissive rules: - action: \"*\" resources: [\"*\"] effect: allow conditions: - type: tag key: Environment value: development read-only For monitoring and auditing:\nname: read-only rules: - action: query resources: [\"*\"] effect: allow - action: \"*\" resources: [\"*\"] effect: deny cost-conscious Limit expensive operations:\nname: cost-conscious rules: - action: create resources: [\"ec2/*\"] effect: deny conditions: - type: instance_type values: [\"*.xlarge\", \"*.2xlarge\", \"*.4xlarge\"] operator: matches message: \"Large instances require approval\" - action: create resources: [\"rds/*\"] effect: require_approval Applying Policies To Agents c2g agent update prod-infra --policies production-safety,cost-conscious To Workspaces Apply default policies to all new agents:\nc2g workspace update --default-policies production-safety Policy Inheritance Policies are evaluated in order:\nAgent-specific policies Workspace default policies Built-in policies The first matching rule wins.\nTesting Policies Dry Run Test what a policy would do:\nc2g policy test production-safety \\ --action delete \\ --resource \"ec2/i-abc123\" Output:\nPolicy: production-safety Action: delete Resource: ec2/i-abc123 Result: REQUIRE_APPROVAL Reason: Rule \"delete-requires-approval\" matched Approvers: admin, ops-team Policy Simulator Test complex scenarios:\nc2g policy simulate -f scenario.yaml # scenario.yaml scenarios: - name: Delete production database action: delete resource: rds/prod-mysql expected: require_approval - name: Query dev resources action: query resource: ec2/dev-* expected: allow - name: Create expensive instance action: create resource: ec2/new-instance context: instance_type: p3.8xlarge expected: deny Policy Versioning Track policy changes:\n# View history c2g policy history production-safety # View specific version c2g policy show production-safety --version 3 # Rollback to previous version c2g policy rollback production-safety --version 2 Monitoring Policy Usage View Policy Decisions c2g policy decisions --last 24h --policy production-safety Policy Analytics View in dashboard:\nHow often each rule is triggered Approval rates Denial patterns Best Practices Start restrictive â€” Begin with deny-by-default and allow specific actions Use approval for destructive actions â€” Always require approval for deletes in production Test thoroughly â€” Use dry runs and simulations before applying Version control â€” Store policies in git Regular review â€” Audit policy effectiveness quarterly Document reasoning â€” Add descriptions explaining why rules exist Use conditions â€” Make policies context-aware (time, tags, etc.) ","categories":"","description":"Define guardrails for agent behavior and resource access.\n","excerpt":"Define guardrails for agent behavior and resource access.\n","ref":"/en/docs/admin/policies/","tags":"","title":"Policies"},{"body":"The Cloud2Gether API allows you to programmatically interact with agents, manage resources, and automate workflows.\nBase URL https://api.cloud2gether.com/v1 Authentication All API requests require authentication using an API key.\nAPI Key Authentication Include your API key in the Authorization header:\ncurl -X GET https://api.cloud2gether.com/v1/agents \\ -H \"Authorization: Bearer YOUR_API_KEY\" Generating API Keys Go to Dashboard â†’ Settings â†’ API Keys Click Generate New Key Set permissions and expiration Copy and securely store the key Rate Limits Plan Requests/minute Requests/day Free 60 1,000 Pro 300 10,000 Enterprise Custom Custom Rate limit headers are included in responses:\nX-RateLimit-Limit: 300 X-RateLimit-Remaining: 299 X-RateLimit-Reset: 1704067200 Response Format All responses are JSON with consistent structure:\nSuccess Response { \"data\": { ... }, \"meta\": { \"request_id\": \"req_abc123\", \"timestamp\": \"2024-01-15T10:30:00Z\" } } Error Response { \"error\": { \"code\": \"invalid_request\", \"message\": \"Missing required field: name\", \"details\": { \"field\": \"name\", \"reason\": \"required\" } }, \"meta\": { \"request_id\": \"req_abc123\" } } API Sections Agents API Create, manage, and interact with AI agents. [View endpoints â†’](agents/) Workflows API Create and manage automated workflows. [View endpoints â†’](workflows/) Resources API Query and manage cloud resources. [View endpoints â†’](resources/) Webhooks Receive real-time notifications for events. [View details â†’](webhooks/) SDKs Client libraries for Python, Go, JavaScript, and more. [View SDKs â†’](sdks/) Quick Examples List Agents curl -X GET https://api.cloud2gether.com/v1/agents \\ -H \"Authorization: Bearer $API_KEY\" Run Agent Command curl -X POST https://api.cloud2gether.com/v1/agents/my-agent/run \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{\"command\": \"List all EC2 instances\"}' Create Workflow curl -X POST https://api.cloud2gether.com/v1/workflows \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"daily-cleanup\", \"schedule\": \"0 2 * * *\", \"agent\": \"infra-agent\", \"steps\": [ {\"command\": \"Stop all dev instances\"} ] }' Pagination List endpoints support pagination:\nGET /v1/agents?limit=20\u0026offset=40 Response includes pagination info:\n{ \"data\": [...], \"meta\": { \"total\": 150, \"limit\": 20, \"offset\": 40, \"has_more\": true } } Filtering and Sorting Many endpoints support filtering and sorting:\n# Filter by status GET /v1/agents?status=running # Sort by creation date GET /v1/workflows?sort=-created_at # Multiple filters GET /v1/resources?provider=aws\u0026type=ec2 Versioning The API version is included in the URL path. The current version is v1.\nBreaking changes will result in a new version. Non-breaking additions may be made to existing versions.\nOpenAPI Specification Download the full OpenAPI specification:\nopenapi.yaml openapi.json ","categories":"","description":"Complete reference for the Cloud2Gether REST API and SDKs.\n","excerpt":"Complete reference for the Cloud2Gether REST API and SDKs.\n","ref":"/en/docs/api/","tags":"","title":"API Reference"},{"body":"Cloud2Gether connects to your cloud providers to manage infrastructure through AI agents.\nSupported Providers Provider Status Services AWS Full support EC2, S3, RDS, Lambda, ECS, EKS, and 200+ services Azure Full support VMs, Storage, Functions, AKS, and 100+ services GCP Full support Compute Engine, Cloud Storage, Functions, GKE Kubernetes Full support Any cluster (managed or self-hosted) DigitalOcean Beta Droplets, Spaces, Kubernetes Oracle Cloud Beta Compute, Storage Adding Providers AWS Option 1: IAM Role (Recommended) Create an IAM role in your AWS account: c2g provider add aws --method role This generates a CloudFormation template. Deploy it:\naws cloudformation create-stack \\ --stack-name Cloud2GetherRole \\ --template-body file://cloud2gether-role.yaml \\ --capabilities CAPABILITY_IAM The role will be automatically detected. Option 2: Access Keys c2g provider add aws \\ --access-key-id AKIAIOSFODNN7EXAMPLE \\ --secret-access-key wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \\ --region us-east-1 Required IAM Permissions Minimum policy for read-only access:\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ec2:Describe*\", \"rds:Describe*\", \"s3:List*\", \"s3:GetBucket*\", \"lambda:List*\", \"lambda:Get*\", \"ecs:Describe*\", \"ecs:List*\" ], \"Resource\": \"*\" } ] } For full management capabilities, see our AWS IAM policy templates.\nAzure Option 1: Service Principal # Create service principal az ad sp create-for-rbac --name \"Cloud2Gether\" --role Contributor # Add to Cloud2Gether c2g provider add azure \\ --tenant-id YOUR_TENANT_ID \\ --client-id YOUR_CLIENT_ID \\ --client-secret YOUR_CLIENT_SECRET \\ --subscription-id YOUR_SUBSCRIPTION_ID Option 2: Managed Identity For Azure-hosted applications:\nc2g provider add azure --method managed-identity Required Roles Assign at subscription level:\nReader â€” For read-only access Contributor â€” For full management GCP Option 1: Service Account Key Create a service account: gcloud iam service-accounts create cloud2gether \\ --display-name \"Cloud2Gether\" gcloud projects add-iam-policy-binding YOUR_PROJECT \\ --member \"serviceAccount:cloud2gether@YOUR_PROJECT.iam.gserviceaccount.com\" \\ --role \"roles/editor\" gcloud iam service-accounts keys create key.json \\ --iam-account cloud2gether@YOUR_PROJECT.iam.gserviceaccount.com Add to Cloud2Gether: c2g provider add gcp \\ --project-id YOUR_PROJECT_ID \\ --key-file key.json Option 2: Workload Identity For GKE-hosted applications:\nc2g provider add gcp --method workload-identity Kubernetes Kubeconfig c2g provider add kubernetes \\ --name prod-cluster \\ --kubeconfig ~/.kube/config \\ --context production Service Account # Create service account kubectl create serviceaccount cloud2gether # Create cluster role binding kubectl create clusterrolebinding cloud2gether \\ --clusterrole=cluster-admin \\ --serviceaccount=default:cloud2gether # Get token c2g provider add kubernetes \\ --name prod-cluster \\ --server https://cluster.example.com \\ --token $(kubectl get secret -o jsonpath='{.data.token}' | base64 -d) Managing Providers List Providers c2g provider list Output:\nNAME TYPE STATUS REGIONS/PROJECTS ADDED aws-prod aws healthy us-east-1, us-west-2 2024-01-10 azure-main azure healthy East US, West US 2024-01-12 gcp-project gcp healthy my-project-id 2024-01-14 prod-cluster kubernetes healthy production-context 2024-01-15 Check Provider Health c2g provider check aws-prod Output:\nProvider: aws-prod Status: Healthy Connectivity: âœ“ Connected Permissions: âœ“ ec2:DescribeInstances âœ“ s3:ListBuckets âœ“ rds:DescribeDBInstances âš  lambda:InvokeFunction (missing) Credential Status: Type: IAM Role Expires: Never (role-based) Last rotated: N/A Resources discovered: 234 Last sync: 5 minutes ago Update Provider c2g provider update aws-prod --regions us-east-1,us-west-2,eu-west-1 Remove Provider c2g provider remove aws-prod Rotating Credentials Manual Rotation c2g provider rotate aws-prod This will:\nGenerate new credentials Verify they work Update the provider Revoke old credentials Automatic Rotation Configure automatic rotation:\nc2g provider update aws-prod --auto-rotate --rotation-interval 90d Or in provider configuration:\nproviders: - name: aws-prod type: aws auto_rotate: true rotation_interval: 90d rotation_notification: \"#security\" Multi-Account Setup AWS Organizations Connect multiple AWS accounts:\n# Add organization management account c2g provider add aws \\ --name aws-org \\ --method organization-role \\ --management-account 123456789012 Cloud2Gether will discover and connect to all member accounts.\nAzure Management Groups c2g provider add azure \\ --management-group-id my-management-group GCP Folders c2g provider add gcp \\ --folder-id 123456789 Provider Scoping Limit which resources agents can access:\nprovider: name: aws-prod type: aws scope: regions: - us-east-1 - us-west-2 tags: Environment: production exclude_resources: - \"arn:aws:ec2:*:*:instance/i-sensitive*\" Troubleshooting Connection Issues # Debug connection c2g provider debug aws-prod # Test specific permissions c2g provider test-permission aws-prod ec2:DescribeInstances Credential Issues # Verify credentials c2g provider verify aws-prod # Force re-authentication c2g provider reauthenticate aws-prod Common Errors Error Cause Solution AccessDenied Missing IAM permissions Add required policies ExpiredToken Credentials expired Rotate credentials InvalidClientTokenId Wrong access key Check access key ID ThrottlingException Rate limited Reduce discovery frequency Best Practices Use roles over keys â€” IAM roles, service principals, and service accounts are more secure Least privilege â€” Grant only necessary permissions Enable auto-rotation â€” Rotate credentials regularly Multi-account strategy â€” Use organization-level access for large deployments Scope providers â€” Limit access to relevant regions and resources Monitor usage â€” Review API calls and access patterns ","categories":"","description":"Connect and configure cloud provider credentials.\n","excerpt":"Connect and configure cloud provider credentials.\n","ref":"/en/docs/admin/providers/","tags":"","title":"Cloud Providers"},{"body":"The Deployment Agent manages application deployments across your infrastructure with intelligent rollout strategies.\nCapabilities Category Operations Deployments Deploy applications with various strategies Rollbacks Quickly revert to previous versions Canary Releases Gradual rollouts with automatic rollback Blue-Green Zero-downtime deployments Environment Management Manage dev, staging, production Release Tracking Track whatâ€™s deployed where Deployment c2g agent deploy deployment \\ --name release-manager \\ --providers aws,kubernetes Configuration name: release-manager type: deployment providers: - name: aws services: [ecs, lambda, codedeploy] - name: kubernetes clusters: [prod-cluster, staging-cluster] settings: # Default deployment strategy default_strategy: rolling # Health check wait time health_check_timeout: 5m # Auto-rollback on failure auto_rollback: true notifications: slack: \"#deployments\" Deployment Operations Simple Deployment \u003e Deploy api-service v2.3.1 to staging Deploying api-service:v2.3.1 to staging... Strategy: Rolling Update â€¢ Current version: v2.3.0 â€¢ Target version: v2.3.1 â€¢ Replicas: 4 Progress: âœ“ Pulled image api-service:v2.3.1 âœ“ Started new replica 1/4 âœ“ Health check passed âœ“ Started new replica 2/4 âœ“ Health check passed âœ“ Started new replica 3/4 âœ“ Health check passed âœ“ Started new replica 4/4 âœ“ Health check passed âœ“ Terminated old replicas Deployment complete! Duration: 3m 24s All 4 replicas running v2.3.1 Blue-Green Deployment \u003e Deploy frontend v4.0.0 to production with blue-green strategy Initiating blue-green deployment... Current (Blue): frontend:v3.9.0 â€¢ Running on: alb-frontend-blue â€¢ Instances: 8 New (Green): frontend:v4.0.0 â€¢ Deploying to: alb-frontend-green â€¢ Instances: 8 Progress: âœ“ Launched green environment âœ“ Deployed v4.0.0 to green âœ“ Health checks passing âœ“ Smoke tests passed Ready to switch traffic: â€¢ Blue (current): 100% traffic â€¢ Green (new): 0% traffic Switch traffic to green? [y/N] y Switching traffic... âœ“ Updated Route 53 to green âœ“ Traffic now flowing to v4.0.0 âœ“ Blue environment on standby Deployment complete! Blue environment will be terminated in 1 hour unless rollback is needed. Canary Deployment \u003e Deploy payment-service v3.0.0 to production with canary Starting canary deployment... Strategy: Canary Release â€¢ Initial canary: 5% â€¢ Full rollout: 30m per stage â€¢ Rollback on: error_rate \u003e 1% OR latency_p99 \u003e 500ms Stage 1: 5% traffic âœ“ Deployed 1 canary replica âœ“ Routing 5% traffic to canary â³ Monitoring for 10 minutes... Metrics: â€¢ Error rate: 0.02% âœ“ â€¢ Latency p99: 245ms âœ“ â€¢ Success rate: 99.98% âœ“ âœ“ Stage 1 passed Stage 2: 25% traffic âœ“ Scaled to 2 canary replicas âœ“ Routing 25% traffic â³ Monitoring for 10 minutes... Metrics: â€¢ Error rate: 0.05% âœ“ â€¢ Latency p99: 252ms âœ“ âœ“ Stage 2 passed Stage 3: 50% traffic ... Stage 4: 100% traffic âœ“ Full rollout complete âœ“ All replicas running v3.0.0 Canary deployment successful! Total duration: 45 minutes Rollback \u003e Rollback api-service to previous version Current: api-service:v2.3.1 Previous: api-service:v2.3.0 Rolling back... âœ“ Pulled image v2.3.0 âœ“ Updated deployment âœ“ 4/4 replicas running v2.3.0 âœ“ Health checks passing Rollback complete! Duration: 1m 45s Note: v2.3.1 marked as failed in release history. Environment Management View Environments \u003e Show what's deployed in each environment â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Deployment Status â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Production: Service Version Replicas Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ api-service v2.3.1 8 healthy frontend v4.0.0 6 healthy payment-service v3.0.0 4 healthy worker v1.8.2 10 healthy Staging: Service Version Replicas Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ api-service v2.4.0 2 healthy frontend v4.1.0 2 healthy payment-service v3.0.0 2 healthy worker v1.9.0 2 healthy Development: Service Version Replicas Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ api-service v2.4.0 1 healthy frontend v4.1.0 1 healthy Promote Between Environments \u003e Promote api-service from staging to production Comparing versions: â€¢ Staging: v2.4.0 â€¢ Production: v2.3.1 Changes in v2.4.0: â€¢ feat: Add pagination to list endpoints â€¢ fix: Memory leak in websocket handler â€¢ chore: Update dependencies Staging metrics (last 7 days): â€¢ Error rate: 0.01% â€¢ Avg latency: 45ms â€¢ No incidents Promote v2.4.0 to production? [y/N] y Deploying to production with rolling strategy... âœ“ 8/8 replicas updated âœ“ Health checks passing Promotion complete! Release Tracking Release History \u003e Show release history for api-service â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” api-service Release History â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Version Deployed Status Duration Deployed By â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.4.0 staging 2h ago current 2m 15s jane@company.com v2.3.1 production 3d ago current 3m 24s john@company.com v2.3.0 production 7d ago replaced 2m 58s john@company.com v2.2.5 production 14d ago replaced 3m 12s jane@company.com v2.2.4 production 14d ago rollback 1m 45s auto-rollback v2.2.3 production 21d ago replaced 2m 34s deploy-pipeline Compare Versions \u003e Compare v2.3.0 and v2.3.1 for api-service Comparing api-service versions: v2.3.0 â†’ v2.3.1 Commits: 12 â€¢ fix: Handle null user in auth middleware â€¢ feat: Add rate limiting to public endpoints â€¢ perf: Optimize database queries for listings â€¢ chore: Update to Node 20 ... Files changed: 34 Dependencies: â€¢ express: 4.18.2 â†’ 4.19.0 â€¢ pg: 8.11.0 â†’ 8.11.3 (security fix) Config changes: â€¢ New env var: RATE_LIMIT_WINDOW â€¢ New env var: RATE_LIMIT_MAX Database migrations: 1 â€¢ 20240115_add_rate_limit_table.sql Deployment Workflows Continuous Deployment name: Auto-Deploy to Staging trigger: type: github event: push branch: main repository: myorg/api-service agent: release-manager steps: - command: \"Build and push image for commit {{ .commit_sha }}\" output: image - command: \"Deploy {{ .image.tag }} to staging\" - wait: 5m reason: \"Stabilization period\" - command: \"Run integration tests against staging\" output: tests - if: \"{{ .tests.passed }}\" then: - notify: channel: \"#deployments\" message: \"âœ… {{ .image.tag }} deployed to staging\" else: - command: \"Rollback staging to previous version\" - notify: channel: \"#deployments\" message: \"âŒ Deployment failed, rolled back\" Production Release name: Production Release trigger: manual inputs: - name: service type: string required: true - name: version type: string required: true - name: strategy type: select options: [rolling, canary, blue-green] default: canary agent: release-manager steps: - command: \"Verify {{ .inputs.service }}:{{ .inputs.version }} exists and is tested\" output: verification - if: \"{{ not .verification.ready }}\" then: - notify: channel: \"#deployments\" message: \"âš ï¸ {{ .inputs.version }} not ready for production\" - command: \"Deploy {{ .inputs.service }}:{{ .inputs.version }} to production using {{ .inputs.strategy }} strategy\" output: deployment - notify: channel: \"#deployments\" message: | ğŸš€ Production Release Service: {{ .inputs.service }} Version: {{ .inputs.version }} Strategy: {{ .inputs.strategy }} Status: {{ .deployment.status }} Duration: {{ .deployment.duration }} Safety Features Deployment Locks Prevent concurrent deployments:\n\u003e Deploy frontend v4.1.0 to production âš ï¸ Deployment lock active Another deployment is in progress: Service: api-service Version: v2.4.0 Started: 5 minutes ago By: john@company.com Wait for current deployment to complete or override? [wait/override] Freeze Periods Block deployments during critical times:\nfreeze_periods: - name: Holiday Freeze start: \"2024-12-20T00:00:00Z\" end: \"2025-01-02T00:00:00Z\" environments: [production] exceptions: [security-patches] Approval Requirements approval: production: required: true approvers: [\"release-manager\", \"tech-lead\"] timeout: 2h Permissions Required { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ecs:*\", \"ecr:*\", \"codedeploy:*\", \"lambda:UpdateFunctionCode\", \"lambda:PublishVersion\", \"elasticloadbalancing:*\" ], \"Resource\": \"*\" } ] } ","categories":"","description":"Handle CI/CD, releases, rollbacks, and deployment strategies.\n","excerpt":"Handle CI/CD, releases, rollbacks, and deployment strategies.\n","ref":"/en/docs/ai-agents/deployment/","tags":"","title":"Deployment Agent"},{"body":"Cloud2Gether integrates with the tools your team already uses.\nAvailable Integrations Integration Description Slack Chat with agents, receive alerts Microsoft Teams Chat with agents, receive alerts PagerDuty Incident management and alerting Opsgenie Incident management and alerting Datadog Monitoring integration GitHub Deployment triggers, PR automation GitLab Deployment triggers, MR automation Jira Issue tracking integration Webhooks Custom integrations Slack Setup Go to Settings â†’ Integrations in the dashboard Click Add Slack Authorize Cloud2Gether in your Slack workspace Select which channels to enable Usage Mention the Cloud2Gether bot to interact with agents:\n@cloud2gether list all EC2 instances Or use slash commands:\n/c2g status # Show agent status /c2g run [agent] [command] /c2g workflow run [name] Channel Notifications Configure channels for different alert types:\nnotifications: slack: - channel: \"#ops-alerts\" events: [agent_error, high_cost, security_issue] - channel: \"#deployments\" events: [deployment_started, deployment_completed] - channel: \"#cost-reports\" events: [weekly_cost_report] Interactive Messages Some notifications include interactive buttons:\nAcknowledge â€” Mark alert as seen Investigate â€” Open detailed view Execute â€” Run suggested action Microsoft Teams Setup Go to Settings â†’ Integrations Click Add Microsoft Teams Sign in with your Microsoft account Select teams and channels Usage Mention the bot in channels:\n@Cloud2Gether show me unhealthy services Or use the personal chat for private queries.\nTabs and Connectors Install the Cloud2Gether tab in channels for:\nReal-time dashboard widgets Quick agent access Activity feeds PagerDuty Setup In PagerDuty, create an API key with full access In Cloud2Gether, go to Settings â†’ Integrations Click Add PagerDuty and enter your API key Map services to Cloud2Gether agents Incident Creation Agents can create PagerDuty incidents:\n- notify: type: pagerduty service: cloud-infrastructure severity: high message: \"Database connection pool exhausted\" details: resource: \"rds-prod-primary\" metric: \"connection_count\" value: 500 Incident Response When incidents trigger, agents can:\nAutomatically gather diagnostic information Suggest remediation steps Execute approved runbooks Bi-directional Sync Incidents from PagerDuty can trigger Cloud2Gether workflows Cloud2Gether can resolve incidents after remediation Datadog Setup Generate a Datadog API key and app key In Cloud2Gether, add the Datadog integration Configure which metrics to sync Features Metrics Correlation â€” Agents can query Datadog metrics Alert Forwarding â€” Datadog monitors trigger Cloud2Gether workflows Custom Dashboards â€” Embed Cloud2Gether widgets in Datadog Example Workflow name: Datadog Alert Response trigger: type: datadog monitor: high_error_rate agent: infrastructure steps: - command: \"Investigate high error rate on {{ .resource }}\" - command: \"Scale up if load is the cause\" GitHub Setup Install the Cloud2Gether GitHub App Select repositories to enable Configure triggers and permissions Features Deployment Triggers Deploy when PRs merge:\nname: Auto Deploy on Merge trigger: type: github event: pull_request.merged branch: main repository: myorg/myapp agent: deployment steps: - command: \"Deploy latest main to staging\" PR Automation Agents can comment on PRs:\nInfrastructure cost impact Security scan results Deployment preview links Status Checks Add Cloud2Gether checks to PRs:\nCost estimation Policy compliance Security scanning GitLab Similar to GitHub integration:\nConfigure GitLab OAuth Select projects Set up webhooks Supports:\nPipeline triggers MR automation Registry integration Webhooks For custom integrations, use webhooks.\nOutgoing Webhooks Send events to external systems:\nwebhooks: - name: custom-alerting url: https://alerts.example.com/webhook events: - agent.error - cost.threshold_exceeded headers: Authorization: Bearer ${WEBHOOK_TOKEN} Incoming Webhooks Trigger workflows from external systems:\ncurl -X POST https://api.cloud2gether.com/webhooks/your-webhook-id \\ -H \"Authorization: Bearer YOUR_TOKEN\" \\ -H \"Content-Type: application/json\" \\ -d '{\"event\": \"deploy\", \"version\": \"v2.3.1\"}' Integration Best Practices Limit permissions â€” Only grant necessary access Use dedicated service accounts â€” Donâ€™t use personal accounts Monitor API usage â€” Watch for rate limits Test in staging â€” Verify integrations before production Document setup â€” Record configuration for your team ","categories":"","description":"Connect Cloud2Gether with Slack, Teams, PagerDuty, and other tools.\n","excerpt":"Connect Cloud2Gether with Slack, Teams, PagerDuty, and other tools.\n","ref":"/en/docs/user-guide/integrations/","tags":"","title":"Integrations"},{"body":"Webhooks allow you to receive HTTP callbacks when events occur in Cloud2Gether.\nOverview When you configure a webhook, Cloud2Gether will send HTTP POST requests to your specified URL whenever matching events occur.\nCreating a Webhook Via API curl -X POST https://api.cloud2gether.com/v1/webhooks \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"my-webhook\", \"url\": \"https://your-server.com/webhook\", \"events\": [\"agent.command.completed\", \"workflow.failed\"], \"secret\": \"your-webhook-secret\" }' Via Dashboard Go to Settings â†’ Webhooks Click Add Webhook Enter URL and select events Save and copy the signing secret Webhook Events Agent Events Event Description agent.created Agent was created agent.deleted Agent was deleted agent.started Agent started running agent.stopped Agent was stopped agent.error Agent encountered an error agent.command.started Command execution started agent.command.completed Command execution completed agent.command.failed Command execution failed Workflow Events Event Description workflow.created Workflow was created workflow.started Workflow execution started workflow.completed Workflow completed successfully workflow.failed Workflow execution failed workflow.step.completed Individual step completed Resource Events Event Description resource.created Resource was created resource.modified Resource was modified resource.deleted Resource was deleted Cost Events Event Description cost.budget.threshold Budget threshold reached cost.anomaly.detected Cost anomaly detected Security Events Event Description security.issue.detected Security issue found security.issue.resolved Security issue resolved Webhook Payload Headers Content-Type: application/json X-C2G-Event: agent.command.completed X-C2G-Signature: sha256=... X-C2G-Timestamp: 1704067200 X-C2G-Delivery-ID: del_abc123 Body Structure { \"id\": \"evt_abc123\", \"type\": \"agent.command.completed\", \"created_at\": \"2024-01-15T10:30:00Z\", \"data\": { \"agent_id\": \"agent_xyz\", \"agent_name\": \"prod-infra\", \"command\": \"List EC2 instances\", \"result\": \"Found 47 instances...\", \"duration_ms\": 2340, \"user\": \"user@example.com\" } } Verifying Signatures Verify webhook authenticity using the signature:\nPython import hmac import hashlib def verify_webhook(payload: bytes, signature: str, secret: str) -\u003e bool: expected = hmac.new( secret.encode(), payload, hashlib.sha256 ).hexdigest() return hmac.compare_digest(f\"sha256={expected}\", signature) # In your webhook handler from flask import Flask, request app = Flask(__name__) WEBHOOK_SECRET = \"your-secret\" @app.route('/webhook', methods=['POST']) def webhook(): signature = request.headers.get('X-C2G-Signature') if not verify_webhook(request.data, signature, WEBHOOK_SECRET): return 'Invalid signature', 401 event = request.json print(f\"Received event: {event['type']}\") return 'OK', 200 JavaScript const crypto = require('crypto'); const express = require('express'); const app = express(); const WEBHOOK_SECRET = 'your-secret'; function verifyWebhook(payload, signature, secret) { const expected = crypto .createHmac('sha256', secret) .update(payload) .digest('hex'); return crypto.timingSafeEqual( Buffer.from(`sha256=${expected}`), Buffer.from(signature) ); } app.post('/webhook', express.raw({type: 'application/json'}), (req, res) =\u003e { const signature = req.headers['x-c2g-signature']; if (!verifyWebhook(req.body, signature, WEBHOOK_SECRET)) { return res.status(401).send('Invalid signature'); } const event = JSON.parse(req.body); console.log(`Received event: ${event.type}`); res.send('OK'); }); Go package main import ( \"crypto/hmac\" \"crypto/sha256\" \"encoding/hex\" \"io\" \"net/http\" ) func verifyWebhook(payload []byte, signature, secret string) bool { mac := hmac.New(sha256.New, []byte(secret)) mac.Write(payload) expected := \"sha256=\" + hex.EncodeToString(mac.Sum(nil)) return hmac.Equal([]byte(expected), []byte(signature)) } func webhookHandler(w http.ResponseWriter, r *http.Request) { body, _ := io.ReadAll(r.Body) signature := r.Header.Get(\"X-C2G-Signature\") if !verifyWebhook(body, signature, \"your-secret\") { http.Error(w, \"Invalid signature\", http.StatusUnauthorized) return } // Process event w.Write([]byte(\"OK\")) } Retry Policy Failed webhook deliveries are retried with exponential backoff:\nAttempt Delay 1 Immediate 2 1 minute 3 5 minutes 4 30 minutes 5 2 hours After 5 failed attempts, the delivery is marked as failed.\nManaging Webhooks List Webhooks curl -X GET https://api.cloud2gether.com/v1/webhooks \\ -H \"Authorization: Bearer $API_KEY\" Update Webhook curl -X PATCH https://api.cloud2gether.com/v1/webhooks/wh_abc123 \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"events\": [\"agent.command.completed\", \"agent.error\"], \"enabled\": true }' Delete Webhook curl -X DELETE https://api.cloud2gether.com/v1/webhooks/wh_abc123 \\ -H \"Authorization: Bearer $API_KEY\" View Delivery History curl -X GET https://api.cloud2gether.com/v1/webhooks/wh_abc123/deliveries \\ -H \"Authorization: Bearer $API_KEY\" Testing Webhooks Send Test Event curl -X POST https://api.cloud2gether.com/v1/webhooks/wh_abc123/test \\ -H \"Authorization: Bearer $API_KEY\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"event_type\": \"agent.command.completed\" }' Using webhook.site For development, use webhook.site to inspect payloads:\nGo to webhook.site and copy your unique URL Create a webhook with that URL Trigger events and view payloads on webhook.site Best Practices Always verify signatures â€” Prevent spoofed requests Respond quickly â€” Return 200 within 5 seconds Process asynchronously â€” Queue events for processing Handle duplicates â€” Events may be delivered more than once Use HTTPS â€” Encrypt webhook traffic Monitor deliveries â€” Watch for failed deliveries in the dashboard ","categories":"","description":"Receive real-time notifications for Cloud2Gether events.\n","excerpt":"Receive real-time notifications for Cloud2Gether events.\n","ref":"/en/docs/api/webhooks/","tags":"","title":"Webhooks"},{"body":"This section covers administrative tasks for Cloud2Gether, including user management, security configuration, and workspace settings.\nTopics User Management Add team members, configure roles, and set up SSO. [Learn more â†’](users/) Security \u0026 Compliance Configure security settings, policies, and audit logging. [Learn more â†’](security/) Policies Define guardrails for agent behavior and resource access. [Learn more â†’](policies/) Cloud Providers Connect and configure cloud provider credentials. [Learn more â†’](providers/) Workspace Settings Configure workspace-level settings and preferences. [Learn more â†’](settings/) FAQ Frequently asked questions and troubleshooting. [Learn more â†’](faq/) Quick Links Add a new user Configure SSO Create a policy Rotate credentials View audit logs ","categories":"","description":"Configure settings, manage users, and set up security policies for your Cloud2Gether workspace.\n","excerpt":"Configure settings, manage users, and set up security policies for â€¦","ref":"/en/docs/admin/","tags":"","title":"Administration"},{"body":"Follow these best practices to use Cloud2Gether effectively and safely.\nAgent Management Use Specialized Agents Deploy agents for specific purposes rather than one agent for everything:\nAgent Purpose prod-infra Production infrastructure management dev-infra Development environment security-audit Security scanning and compliance cost-optimizer Cost monitoring and optimization Benefits:\nClearer audit trails Easier policy management Better context for each domain Set Appropriate Policies Always configure policies before deploying agents:\n# production-agent-policy.yaml name: production-safety rules: # Require approval for destructive actions - action: delete resources: [\"*\"] require: approval approvers: [\"ops-team\"] # Block modifications to critical resources - action: modify resources: [\"database/*\", \"network/*\"] require: approval # Allow read operations - action: query resources: [\"*\"] allow: true Monitor Agent Activity Regularly review agent actions:\n# View recent activity c2g agent activity prod-infra --last 24h # Export audit logs c2g audit export --format csv --last 30d Command Patterns Start with Queries Before making changes, understand current state:\n\u003e Show me all instances tagged Environment=production (review the list) \u003e Which of these have less than 20% CPU utilization? (understand the scope) \u003e Stop the ones that are definitely unused (make informed decisions) Use Dry Runs Test changes before applying:\n\u003e Dry run: Delete all unattached EBS volumes Would delete 12 volumes: â€¢ vol-abc123 (500GB) - created 90 days ago â€¢ vol-def456 (100GB) - created 45 days ago ... Total size: 2.3TB Estimated monthly savings: $230 This was a dry run. No changes were made. Be Specific About Scope Specify regions, accounts, and filters:\n# Good \u003e List EC2 instances in us-east-1 with tag Team=backend # Risky \u003e List all instances Confirm Understanding When uncertain, ask for clarification:\n\u003e Stop all non-production instances I found instances in these environments: â€¢ dev: 15 instances â€¢ staging: 8 instances â€¢ test: 5 instances â€¢ production: 0 (excluded) Stop all 28 instances? [y/N] Security Best Practices Least Privilege Access Configure cloud credentials with minimum required permissions:\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ec2:Describe*\", \"ec2:StartInstances\", \"ec2:StopInstances\" ], \"Resource\": \"*\", \"Condition\": { \"StringEquals\": { \"ec2:ResourceTag/ManagedBy\": \"cloud2gether\" } } } ] } Rotate Credentials Rotate cloud provider credentials regularly:\n# Check credential age c2g provider check aws # Rotate credentials c2g provider rotate aws Enable MFA for Sensitive Operations Require MFA for destructive actions:\npolicies: mfa_required: actions: [delete, terminate, modify] resources: [\"production/*\"] Audit Regularly Review audit logs for unexpected activity:\n# Weekly audit review c2g audit report --last 7d --format summary Cost Management Tag Everything Use consistent tagging for cost allocation:\nrequired_tags: - Environment - Team - Project - CostCenter Set Budgets Create budgets with alerts:\n\u003e Set a budget of $10,000/month for production with alerts at 80% and 100% Created budget: production-monthly â€¢ Limit: $10,000 â€¢ Alert at $8,000 (80%) â†’ #cost-alerts â€¢ Alert at $10,000 (100%) â†’ #ops-oncall Schedule Development Resources Stop non-production resources outside work hours:\nname: dev-hours schedule: \"0 18 * * 1-5\" # 6 PM weekdays agent: dev-infra steps: - command: \"Stop all instances tagged Environment=dev\" --- name: dev-start schedule: \"0 8 * * 1-5\" # 8 AM weekdays agent: dev-infra steps: - command: \"Start instances tagged Environment=dev\" Review Recommendations Act on cost optimization suggestions:\n\u003e Show me this month's cost optimization recommendations Found $2,340/month in potential savings: 1. Right-size instances ($890/month) â€¢ i-abc123: r5.2xlarge â†’ r5.xlarge â€¢ i-def456: m5.xlarge â†’ m5.large 2. Delete unused resources ($650/month) â€¢ 8 unattached EBS volumes â€¢ 3 unused Elastic IPs 3. Reserved Instances ($800/month) â€¢ 5 instances running 24/7 qualify for RIs Apply these recommendations? [y/N] Workflow Best Practices Start Simple Begin with basic workflows and add complexity:\n# Start with this name: daily-report schedule: \"0 9 * * *\" steps: - command: \"Generate infrastructure summary\" - notify: channel: \"#daily-report\" Add Error Handling Include failure notifications:\nsteps: - command: \"Perform backup\" on_failure: - notify: type: pagerduty severity: high message: \"Backup failed\" Version Control Workflows Store workflow definitions in git:\nworkflows/ â”œâ”€â”€ daily-cleanup.yaml â”œâ”€â”€ weekly-report.yaml â”œâ”€â”€ deploy-production.yaml â””â”€â”€ incident-response.yaml Test Before Activating Use dry run mode:\nc2g workflow run my-workflow --dry-run Team Collaboration Use Workspaces Separate environments and teams:\nproduction â€” Production infrastructure staging â€” Pre-production testing team-backend â€” Backend team resources Define Clear Roles Set up roles with appropriate permissions:\nRole Can Do Viewer Query resources, view logs Operator Start/stop, run workflows Admin Create agents, modify policies Owner All actions, billing, users Document Runbooks Create documented procedures:\nname: Database Failover description: | Use this workflow when the primary database is unresponsive. Prerequisites: - Verify primary is actually down - Notify on-call DBA Post-steps: - Update DNS if needed - Verify application connectivity Share Knowledge Use agent conversations for documentation:\n\u003e Document how to add a new node to the Kubernetes cluster To add a new node to the EKS cluster: 1. Create the instance: c2g run prod-infra \"Create new m5.large instance for eks-prod cluster\" 2. Join the cluster: The agent will automatically configure and join the node 3. Verify: c2g run prod-infra \"Verify node eks-node-new is healthy\" Should I save this as a workflow for future use? ","categories":"","description":"Tips and patterns for getting the most out of Cloud2Gether.\n","excerpt":"Tips and patterns for getting the most out of Cloud2Gether.\n","ref":"/en/docs/user-guide/best-practices/","tags":"","title":"Best Practices"},{"body":"The Monitoring Agent provides observability and incident response capabilities for your infrastructure.\nCapabilities Category Operations Observability Query metrics, logs, and traces Alerting Set up alerts and notifications Incident Response Automated diagnostics and remediation SLO Tracking Monitor service level objectives On-Call Support Assist with incident investigation Reporting Generate reliability reports Deployment c2g agent deploy monitoring \\ --name sre-assistant \\ --providers aws,datadog Configuration name: sre-assistant type: monitoring providers: - name: aws services: [cloudwatch, xray] - name: datadog api_key: ${DATADOG_API_KEY} - name: pagerduty api_key: ${PAGERDUTY_API_KEY} settings: # Default time range for queries default_lookback: 1h # Auto-investigate on alert auto_investigate: true notifications: slack: \"#sre\" pagerduty: platform-team Observability Queries Check System Health \u003e How is production doing right now? â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Production Health Dashboard â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Overall Status: âœ“ Healthy Services: Service Status Latency Error Rate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ api-gateway âœ“ 45ms 0.01% user-service âœ“ 32ms 0.00% payment-service âœ“ 89ms 0.02% search-service âš ï¸ 234ms 0.15% notification-svc âœ“ 18ms 0.00% Infrastructure: â€¢ EC2: 47/47 healthy â€¢ RDS: All databases responding â€¢ Redis: 99.9% hit rate â€¢ Kafka: 0 consumer lag Active Alerts: 1 âš ï¸ search-service latency above threshold Recent Events: â€¢ 15m ago: Deployment api-service v2.3.1 â€¢ 2h ago: Auto-scaled worker +2 instances Query Metrics \u003e Show me CPU usage for api-servers over the last 6 hours Querying CloudWatch metrics... api-server CPU Usage (Last 6 Hours) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% â”¤ 80% â”¤ â•­â”€â”€â•® 60% â”¤ â•­â”€â•® â•­â•¯ â•°â•® 40% â”¤ â•­â”€â”€â•¯ â•°â”€â”€â•® â•­â•¯ â•°â”€â”€â•® 20% â”¼â”€â”€â”€â•¯ â•°â”€â”€â”€â”€â”€â”€â•¯ â•°â”€â”€â”€ 0% â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6h 5h 4h 3h 2h 1h now Summary: â€¢ Average: 38% â€¢ Maximum: 82% (at 2:30 PM) â€¢ Minimum: 18% (at 8:00 AM) â€¢ Current: 35% Peak corresponds to daily batch job run. Search Logs \u003e Find errors in api-service logs from the last hour Searching CloudWatch Logs... Found 23 errors in the last hour: Error Distribution: â€¢ DatabaseConnectionError: 12 occurrences â€¢ TimeoutError: 8 occurrences â€¢ ValidationError: 3 occurrences Sample Errors: [2024-01-15 14:23:45] ERROR DatabaseConnectionError Message: Connection pool exhausted Service: api-service Instance: i-abc123 Stack: at getConnection (db.js:45) [2024-01-15 14:25:12] ERROR TimeoutError Message: Request to payment-service timed out Duration: 30005ms Trace ID: abc-123-def Show full error details? [y/N] Trace Analysis \u003e Show me slow requests to /api/orders endpoint Analyzing traces from X-Ray... Slow Requests (\u003e500ms) in Last Hour: 45 P99 Latency Breakdown: /api/orders (avg: 234ms, p99: 1.2s) â””â”€ api-gateway (12ms) â””â”€ order-service (180ms) â”œâ”€ database query (145ms) â† bottleneck â”œâ”€ inventory check (20ms) â””â”€ pricing calculation (12ms) â””â”€ response formatting (8ms) Root Cause Analysis: The database query for order retrieval is slow. Query: SELECT * FROM orders WHERE user_id = ? ORDER BY created_at DESC Recommendations: 1. Add index on (user_id, created_at) 2. Implement pagination if not present 3. Consider caching frequent queries Shall I create a ticket for this optimization? Alerting Create Alert \u003e Alert me if error rate exceeds 1% for any production service Created alert: production-error-rate Configuration: â€¢ Metric: error_rate â€¢ Threshold: \u003e 1% â€¢ Duration: 5 minutes â€¢ Services: all production services â€¢ Notification: #sre, PagerDuty Alert is now active. View Alerts \u003e Show all active alerts â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Active Alerts â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” âš ï¸ search-service-latency (firing for 23m) Metric: p99_latency \u003e 200ms Current: 234ms Service: search-service Runbook: https://wiki/runbooks/search-latency âœ“ No critical alerts Recent Resolved: â€¢ database-connections (resolved 2h ago) â€¢ worker-queue-depth (resolved 5h ago) Incident Response Investigate Alert \u003e Investigate the search-service latency alert Starting investigation... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Incident Investigation: search-service-latency â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Timeline: 14:00 - Normal latency (~80ms p99) 14:15 - Latency started increasing 14:23 - Alert triggered (\u003e200ms) 14:45 - Current (234ms) Correlation Analysis: Recent Changes: âœ— No deployments to search-service âœ— No config changes âš ï¸ Elasticsearch cluster health: YELLOW Infrastructure: â€¢ search-service instances: healthy â€¢ CPU: normal (25%) â€¢ Memory: normal (60%) â€¢ Elasticsearch: 2/3 nodes responding Root Cause Hypothesis: Elasticsearch node es-node-3 is not responding. This is causing increased latency as queries are being served by remaining nodes. Recommended Actions: 1. Check es-node-3 status 2. Restart if unresponsive 3. Consider adding temporary capacity Execute remediation? [y/N] Automated Remediation \u003e Restart es-node-3 and verify cluster health Executing remediation... Step 1: Stop es-node-3 âœ“ Node stopped Step 2: Wait for cluster rebalance â³ Waiting 60 seconds... âœ“ Cluster rebalanced Step 3: Start es-node-3 âœ“ Node started â³ Waiting for node to join cluster... âœ“ Node joined cluster Step 4: Verify cluster health âœ“ Cluster status: GREEN âœ“ All 3 nodes healthy âœ“ All shards allocated Step 5: Verify service latency â³ Monitoring for 5 minutes... âœ“ Latency returned to normal (85ms p99) Remediation complete! Alert will auto-resolve in 5 minutes. Incident summary logged. SLO Tracking View SLOs \u003e Show SLO status for all services â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” SLO Status - January 2024 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” api-gateway Availability: 99.97% (target: 99.9%) âœ“ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 99.97% Error budget remaining: 21 minutes payment-service Availability: 99.89% (target: 99.95%) âš ï¸ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 99.89% Error budget remaining: -4 minutes Latency p99: 95ms (target: \u003c100ms) âœ“ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 95% search-service Availability: 99.95% (target: 99.9%) âœ“ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 99.95% Error budget remaining: 14 minutes Latency p99: 180ms (target: \u003c150ms) âŒ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 120% Budget exhausted: 3 hours ago Set Up SLO \u003e Create an SLO for user-service: 99.9% availability and p99 latency under 100ms Created SLO: user-service-slo Objectives: 1. Availability Target: 99.9% Window: 30 days rolling Alert at: 50% budget consumed 2. Latency Target: p99 \u003c 100ms Window: 30 days rolling Alert at: 50% budget consumed Error Budget: â€¢ Availability: 43 minutes/month â€¢ Latency: 43 minutes of violations/month SLO tracking is now active. Reporting Generate Report \u003e Generate reliability report for last month Generating Monthly Reliability Report... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Reliability Report - December 2023 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Executive Summary: â€¢ Overall Availability: 99.94% â€¢ Total Incidents: 3 â€¢ Total Downtime: 26 minutes â€¢ MTTR: 8.7 minutes Incident Summary: 1. Dec 5 - Database Failover (14 min) Impact: payment-service degraded Root cause: Primary DB disk failure Action: Improved failover automation 2. Dec 12 - Network Partition (8 min) Impact: All services degraded Root cause: AWS AZ connectivity issue Action: Multi-AZ deployment review 3. Dec 28 - Memory Leak (4 min) Impact: api-service restart Root cause: Memory leak in v2.2.4 Action: Fixed in v2.2.5 SLO Performance: All SLOs met âœ“ Trends: â€¢ Incidents: â†“ from 5 (November) â€¢ MTTR: â†“ from 12 minutes â€¢ Availability: â†‘ from 99.91% [PDF generated: reliability-dec-2023.pdf] On-Call Support Quick Diagnostics \u003e I'm on call and got paged for high CPU on prod-api-1 Running diagnostics on prod-api-1 (i-abc123)... Current Status: â€¢ CPU: 94% (critical) â€¢ Memory: 67% (normal) â€¢ Disk: 45% (normal) â€¢ Network: 1.2 Gbps (normal) Top Processes: PID CPU% Process â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 12345 89% node /app/server.js 12346 3% datadog-agent 12347 1% sshd Recent Events: â€¢ 5 min ago: Traffic spike (+40%) â€¢ 10 min ago: No changes Analysis: The Node.js process is consuming high CPU due to increased traffic. This appears to be organic growth. Recommendations: 1. Scale out: Add 2 more instances 2. Enable auto-scaling if not configured 3. Investigate if traffic spike is legitimate Quick Actions: [S]cale out [V]iew request logs [A]dd to auto-scaling group [E]scalate to team What would you like to do? Permissions Required { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"cloudwatch:*\", \"logs:*\", \"xray:*\", \"application-autoscaling:*\", \"autoscaling:*\" ], \"Resource\": \"*\" } ] } ","categories":"","description":"Observe systems, respond to incidents, and maintain reliability.\n","excerpt":"Observe systems, respond to incidents, and maintain reliability.\n","ref":"/en/docs/ai-agents/monitoring/","tags":"","title":"Monitoring Agent"},{"body":"Cloud2Gether provides official SDKs for popular programming languages.\nPython SDK Installation pip install cloud2gether Quick Start from cloud2gether import Client # Initialize client client = Client(api_key=\"your-api-key\") # List agents agents = client.agents.list() for agent in agents: print(f\"{agent.name}: {agent.status}\") # Run a command result = client.agents.run( agent_id=\"prod-infra\", command=\"List all EC2 instances\" ) print(result.text) Working with Agents from cloud2gether import Client client = Client() # Create an agent agent = client.agents.create( name=\"my-agent\", type=\"infrastructure\", providers=[\"aws\"] ) # Get agent details agent = client.agents.get(\"prod-infra\") print(f\"Status: {agent.status}\") print(f\"Resources managed: {agent.stats.resources_managed}\") # Update agent client.agents.update( agent_id=\"prod-infra\", config={\"discovery_interval\": \"10m\"} ) # Delete agent client.agents.delete(\"my-agent\") Interactive Chat from cloud2gether import Client client = Client() # Start a chat session session = client.agents.chat(\"prod-infra\") # Send messages response = session.send(\"How many instances are running?\") print(response.message) response = session.send(\"Show me the expensive ones\") print(response.message) # Close session session.close() Streaming Responses from cloud2gether import Client client = Client() # Stream a long-running command for chunk in client.agents.run_stream( agent_id=\"prod-infra\", command=\"Analyze all my infrastructure\" ): print(chunk, end=\"\", flush=True) Async Support import asyncio from cloud2gether import AsyncClient async def main(): client = AsyncClient() # Async list agents = await client.agents.list() # Async run result = await client.agents.run( agent_id=\"prod-infra\", command=\"List S3 buckets\" ) print(result.text) asyncio.run(main()) JavaScript/TypeScript SDK Installation npm install @cloud2gether/sdk # or yarn add @cloud2gether/sdk Quick Start import { Cloud2Gether } from '@cloud2gether/sdk'; const client = new Cloud2Gether({ apiKey: 'your-api-key' }); // List agents const agents = await client.agents.list(); agents.forEach(agent =\u003e { console.log(`${agent.name}: ${agent.status}`); }); // Run a command const result = await client.agents.run('prod-infra', { command: 'List all EC2 instances' }); console.log(result.text); Working with Agents import { Cloud2Gether } from '@cloud2gether/sdk'; const client = new Cloud2Gether(); // Create an agent const agent = await client.agents.create({ name: 'my-agent', type: 'infrastructure', providers: ['aws'] }); // Get agent details const details = await client.agents.get('prod-infra'); console.log(`Status: ${details.status}`); // Update agent await client.agents.update('prod-infra', { config: { discoveryInterval: '10m' } }); // Delete agent await client.agents.delete('my-agent'); Streaming Responses import { Cloud2Gether } from '@cloud2gether/sdk'; const client = new Cloud2Gether(); // Stream responses const stream = client.agents.runStream('prod-infra', { command: 'Analyze my infrastructure' }); for await (const chunk of stream) { process.stdout.write(chunk); } React Hook import { useAgent, useAgentRun } from '@cloud2gether/react'; function InfraStatus() { const { data: agent, isLoading } = useAgent('prod-infra'); const { mutate: runCommand, data: result } = useAgentRun(); if (isLoading) return \u003cdiv\u003eLoading...\u003c/div\u003e; return ( \u003cdiv\u003e \u003ch1\u003e{agent.name}\u003c/h1\u003e \u003cp\u003eStatus: {agent.status}\u003c/p\u003e \u003cbutton onClick={() =\u003e runCommand({ agentId: 'prod-infra', command: 'List instances' })}\u003e List Instances \u003c/button\u003e {result \u0026\u0026 \u003cpre\u003e{result.text}\u003c/pre\u003e} \u003c/div\u003e ); } Go SDK Installation go get github.com/cloud2gether/go-sdk Quick Start package main import ( \"context\" \"fmt\" \"log\" c2g \"github.com/cloud2gether/go-sdk\" ) func main() { client := c2g.NewClient(\"your-api-key\") ctx := context.Background() // List agents agents, err := client.Agents.List(ctx, nil) if err != nil { log.Fatal(err) } for _, agent := range agents { fmt.Printf(\"%s: %s\\n\", agent.Name, agent.Status) } // Run a command result, err := client.Agents.Run(ctx, \"prod-infra\", \u0026c2g.RunOptions{ Command: \"List all EC2 instances\", }) if err != nil { log.Fatal(err) } fmt.Println(result.Text) } Working with Agents package main import ( \"context\" c2g \"github.com/cloud2gether/go-sdk\" ) func main() { client := c2g.NewClient(\"\") ctx := context.Background() // Create an agent agent, _ := client.Agents.Create(ctx, \u0026c2g.CreateAgentInput{ Name: \"my-agent\", Type: \"infrastructure\", Providers: []string{\"aws\"}, }) // Get agent details details, _ := client.Agents.Get(ctx, \"prod-infra\") fmt.Printf(\"Status: %s\\n\", details.Status) // Update agent client.Agents.Update(ctx, \"prod-infra\", \u0026c2g.UpdateAgentInput{ Config: map[string]interface{}{ \"discovery_interval\": \"10m\", }, }) // Delete agent client.Agents.Delete(ctx, \"my-agent\") } CLI Integration Use the SDKs to build custom CLI tools:\nPython Example #!/usr/bin/env python import click from cloud2gether import Client client = Client() @click.group() def cli(): pass @cli.command() @click.argument('agent') @click.argument('command') def run(agent, command): \"\"\"Run a command on an agent.\"\"\" result = client.agents.run(agent, command) click.echo(result.text) @cli.command() def agents(): \"\"\"List all agents.\"\"\" for agent in client.agents.list(): status_color = 'green' if agent.status == 'running' else 'red' click.echo(f\"{agent.name}: \", nl=False) click.secho(agent.status, fg=status_color) if __name__ == '__main__': cli() Error Handling All SDKs provide consistent error handling:\nPython from cloud2gether import Client from cloud2gether.exceptions import ( AuthenticationError, RateLimitError, AgentNotFoundError, APIError ) client = Client() try: result = client.agents.run(\"my-agent\", \"some command\") except AuthenticationError: print(\"Invalid API key\") except RateLimitError as e: print(f\"Rate limited. Retry after {e.retry_after} seconds\") except AgentNotFoundError: print(\"Agent not found\") except APIError as e: print(f\"API error: {e.message}\") JavaScript import { Cloud2Gether, APIError, RateLimitError } from '@cloud2gether/sdk'; const client = new Cloud2Gether(); try { const result = await client.agents.run('my-agent', { command: 'some command' }); } catch (error) { if (error instanceof RateLimitError) { console.log(`Rate limited. Retry after ${error.retryAfter}s`); } else if (error instanceof APIError) { console.log(`API error: ${error.message}`); } } Configuration Environment Variables All SDKs support configuration via environment variables:\nVariable Description C2G_API_KEY API key for authentication C2G_BASE_URL Custom API base URL C2G_TIMEOUT Request timeout in seconds Configuration File Create ~/.cloud2gether/config.yaml:\napi_key: your-api-key base_url: https://api.cloud2gether.com timeout: 30 workspace: default ","categories":"","description":"Client libraries for Python, JavaScript, Go, and more.\n","excerpt":"Client libraries for Python, JavaScript, Go, and more.\n","ref":"/en/docs/api/sdks/","tags":"","title":"SDKs"},{"body":"When the built-in agents donâ€™t fit your needs, you can create custom agents with specific capabilities and behaviors.\nWhen to Use Custom Agents Custom agents are useful for:\nDomain-specific workflows â€” Industry or company-specific processes Specialized integrations â€” Connecting to proprietary systems Custom automation â€” Unique operational patterns Extended capabilities â€” Adding features to existing agent types Creating a Custom Agent Agent Definition Define your agent in YAML:\n# custom-agent.yaml apiVersion: cloud2gether.com/v1 kind: Agent metadata: name: database-admin description: Specialized agent for database operations spec: # Base agent type to extend extends: infrastructure # Custom capabilities capabilities: - database-migrations - query-optimization - backup-management - replication-setup # Knowledge base knowledge: - type: documentation source: https://wiki.company.com/database-runbooks - type: schema source: s3://configs/database-schemas/ # Custom commands commands: - name: optimize-slow-queries description: Analyze and optimize slow database queries handler: | 1. Query slow_log for queries \u003e 1s 2. Analyze execution plans 3. Suggest index improvements 4. Apply with user approval - name: setup-replication description: Configure primary-replica replication parameters: - name: primary type: string required: true - name: replica_count type: integer default: 1 handler: | 1. Verify primary is healthy 2. Create replica instances 3. Configure replication 4. Verify sync status # Policies policies: - name: production-database-safety rules: - action: drop resources: [\"production/*\"] require: dual-approval # Provider configuration providers: - name: aws services: [rds, dynamodb] - name: postgresql connection_string: ${DATABASE_URL} Deploy Custom Agent c2g agent create -f custom-agent.yaml Agent Components Capabilities Define what your agent can do:\ncapabilities: # Built-in capabilities - query # Read data - modify # Make changes - monitor # Watch for changes # Custom capabilities - database-migrations - schema-validation - performance-tuning Knowledge Base Provide context for your agent:\nknowledge: # Documentation - type: documentation source: https://docs.company.com/ refresh: daily # API specifications - type: openapi source: s3://specs/api-spec.yaml # Custom schemas - type: schema source: ./schemas/ # Runbooks - type: runbook source: https://wiki.company.com/runbooks/ Custom Commands Define specialized operations:\ncommands: - name: rotate-credentials description: Rotate database credentials safely parameters: - name: database type: string required: true - name: user type: string required: true approval_required: true handler: | 1. Generate new credentials 2. Update Secrets Manager 3. Update application configs 4. Verify connectivity 5. Revoke old credentials Integrations Connect to external systems:\nintegrations: - name: jira type: issue-tracker config: base_url: https://company.atlassian.net project: OPS api_token: ${JIRA_TOKEN} - name: confluence type: knowledge-base config: base_url: https://company.atlassian.net/wiki space: Engineering - name: custom-api type: http config: base_url: https://internal-api.company.com auth: type: bearer token: ${API_TOKEN} Example: ML Training Agent apiVersion: cloud2gether.com/v1 kind: Agent metadata: name: ml-trainer description: Manage ML training jobs and model deployment spec: extends: infrastructure capabilities: - training-jobs - model-registry - experiment-tracking - gpu-management knowledge: - type: documentation source: https://docs.company.com/ml-platform/ commands: - name: train-model description: Start a training job parameters: - name: experiment type: string required: true - name: config type: file required: true - name: gpu_type type: select options: [p3.2xlarge, p3.8xlarge, p4d.24xlarge] default: p3.2xlarge handler: | 1. Validate training config 2. Reserve GPU instances 3. Pull training data 4. Start training job 5. Monitor progress 6. Log metrics to MLflow - name: deploy-model description: Deploy a model to production parameters: - name: model_uri type: string required: true - name: environment type: select options: [staging, production] handler: | 1. Validate model artifact 2. Run model tests 3. Deploy to SageMaker 4. Update endpoint 5. Verify predictions providers: - name: aws services: [sagemaker, s3, ec2] - name: mlflow tracking_uri: https://mlflow.company.com Example: Compliance Agent apiVersion: cloud2gether.com/v1 kind: Agent metadata: name: compliance-auditor description: Monitor and enforce compliance policies spec: extends: security capabilities: - policy-enforcement - audit-logging - report-generation - remediation knowledge: - type: documentation source: s3://compliance/policies/ - type: regulation sources: - soc2 - hipaa - gdpr commands: - name: compliance-scan description: Run comprehensive compliance scan parameters: - name: framework type: select options: [soc2, hipaa, pci-dss, gdpr, all] default: all handler: | 1. Scan all resources 2. Check against framework requirements 3. Identify violations 4. Generate remediation plan 5. Create compliance report - name: enforce-policy description: Enforce a specific policy parameters: - name: policy_id type: string required: true - name: auto_remediate type: boolean default: false policies: - name: compliance-actions rules: - action: remediate resources: [\"*\"] require: approval unless: auto_remediate_enabled schedules: - name: daily-audit cron: \"0 6 * * *\" command: compliance-scan --framework all Testing Custom Agents Dry Run Test without making changes:\nc2g agent test database-admin --command \"optimize-slow-queries\" --dry-run Sandbox Environment Test in isolated environment:\nc2g agent test database-admin --sandbox Unit Tests Write tests for custom commands:\n# tests/database-admin-tests.yaml tests: - name: optimize-slow-queries-finds-issues command: optimize-slow-queries mock: slow_log: - query: \"SELECT * FROM users\" duration: 2.5s expect: recommendations: 1 - name: setup-replication-validates-primary command: setup-replication parameters: primary: non-existent-db expect: error: \"Primary database not found\" c2g agent test database-admin -f tests/database-admin-tests.yaml Sharing Agents Export Agent c2g agent export database-admin -o database-admin.yaml Import Agent c2g agent import -f database-admin.yaml Agent Registry Publish to your organizationâ€™s registry:\nc2g agent publish database-admin --registry company-agents Install from registry:\nc2g agent install company-agents/database-admin Best Practices Start with built-in agents â€” Extend rather than build from scratch Keep commands focused â€” One command should do one thing well Require approval for dangerous operations â€” Use policies to enforce safety Version your agents â€” Track changes in source control Test thoroughly â€” Use dry runs and sandbox environments Document knowledge sources â€” Help the agent understand context Monitor usage â€” Review how the agent is being used ","categories":"","description":"Build your own agents for specialized use cases.\n","excerpt":"Build your own agents for specialized use cases.\n","ref":"/en/docs/ai-agents/custom/","tags":"","title":"Custom Agents"},{"body":"General What is Cloud2Gether? Cloud2Gether is an agentic DevOps platform that uses AI agents to manage your cloud infrastructure. Instead of writing scripts or clicking through consoles, you can describe what you want in natural language and agents will execute it.\nHow is this different from Terraform or Ansible? Traditional tools require you to write code that describes how to do something. Cloud2Gether agents understand what you want and figure out the how. You can say â€œdeploy my app with zero downtimeâ€ instead of writing deployment scripts.\nWhich cloud providers are supported? We fully support AWS, Azure, GCP, and Kubernetes. DigitalOcean and Oracle Cloud are in beta.\nIs my data secure? Yes. We use TLS 1.3 for all data in transit and AES-256 for data at rest. Weâ€™re SOC 2 Type II certified and offer HIPAA compliance for enterprise customers. See our Security documentation for details.\nAgents What can agents do? Agents can query resources, make changes, set up automations, and respond to incidents. Each agent type specializes in different areas â€” infrastructure, security, cost, deployment, and monitoring.\nCan agents access my production environment? Only if you connect your production cloud accounts and configure appropriate permissions. You control exactly what agents can access through provider connections and policies.\nWill agents make changes without my approval? By default, destructive actions require confirmation. You can configure policies to require approval for any action types youâ€™re concerned about.\nHow do agents learn about my infrastructure? Agents discover resources by connecting to your cloud providersâ€™ APIs. They donâ€™t store your data â€” they query it on demand and use it to understand context for your commands.\nCan I limit what agents can do? Yes, using policies. You can restrict actions, require approvals, set rate limits, and block access to sensitive resources.\nSecurity How do you store my cloud credentials? Credentials are encrypted with workspace-specific keys using AES-256. For AWS, we recommend using IAM roles which donâ€™t require storing long-term credentials at all.\nCan Cloud2Gether employees see my infrastructure? No. We have no access to your cloud providers. Our employees cannot see your resources, data, or credentials.\nWhat happens if Cloud2Gether is compromised? Each workspace uses isolated encryption keys. A breach would not expose credentials without also compromising our key management system. We also support bring-your-own-key (BYOK) for enterprise customers.\nDo you have SOC 2 certification? Yes, weâ€™re SOC 2 Type II certified. Enterprise customers can request our SOC 2 report.\nPricing How is Cloud2Gether priced? Pricing is based on the number of agents and managed resources. See cloud2gether.com/pricing for current plans.\nIs there a free tier? Yes, the free tier includes 1 agent and up to 50 managed resources.\nWhat counts as a managed resource? A managed resource is any cloud resource that an agent can access â€” EC2 instances, S3 buckets, RDS databases, etc. Resources are counted based on your cloud provider connections.\nTechnical Whatâ€™s the uptime SLA? We offer 99.9% uptime for Pro plans and 99.99% for Enterprise. See our status page for current status.\nCan I self-host Cloud2Gether? Enterprise customers can deploy Cloud2Gether in their own infrastructure. Contact sales for details.\nDoes Cloud2Gether work with my CI/CD pipeline? Yes. Use our API or CLI to integrate with any CI/CD system. We also have native integrations with GitHub Actions, GitLab CI, and Jenkins.\nWhat programming languages do you support? We have official SDKs for Python, JavaScript/TypeScript, and Go. The REST API works with any language.\nCan I use Cloud2Gether offline? No, agents require connectivity to your cloud providers and our platform. For air-gapped environments, contact us about enterprise self-hosted options.\nTroubleshooting My agent isnâ€™t responding Check agent status:\nc2g agent status my-agent Common causes:\nAgent is paused â€” resume with c2g agent resume my-agent Provider connection issues â€” check with c2g provider check Workspace limit reached â€” upgrade your plan Commands are failing with permission errors Verify:\nCloud provider credentials are valid: c2g provider verify aws IAM permissions are sufficient: c2g provider check aws Policies allow the action: c2g policy test policy-name --action delete --resource ec2/* Agent is slow to respond Possible causes:\nLarge infrastructure to scan â€” increase discovery interval Complex command â€” break into smaller queries Rate limiting â€” check cloud provider quotas I canâ€™t connect my cloud provider Common issues:\nAWS: IAM permissions insufficient, or STS AssumeRole not configured Azure: Service principal expired, or wrong tenant ID GCP: Service account key invalid, or APIs not enabled Run c2g provider debug provider-name for detailed diagnostics.\nHow do I reset my API key? Generate a new key:\nc2g auth create-key --name \"New Key\" Then revoke the old one:\nc2g auth revoke-key key_abc123 Integration Does Cloud2Gether integrate with Slack? Yes. See Integrations for setup instructions.\nCan I receive alerts via PagerDuty? Yes. Configure the PagerDuty integration in Settings â†’ Integrations.\nHow do I export data to my SIEM? Use our webhook integration or native SIEM connectors (Splunk, Datadog, Elastic). See Security documentation.\nGetting Help How do I contact support? Email: support@cloud2gether.com In-app chat: Click the help icon in the dashboard Community: Discord Is there a community forum? Join our Discord community for discussions, tips, and peer support.\nHow do I report a bug? Email support@cloud2gether.com or open an issue on GitHub.\nHow do I request a feature? Submit feature requests on our feedback board or discuss in Discord.\n","categories":"","description":"Frequently asked questions about Cloud2Gether.\n","excerpt":"Frequently asked questions about Cloud2Gether.\n","ref":"/en/docs/admin/faq/","tags":"","title":"FAQ"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/","tags":"","title":"Cloud2Gether Documentation"},{"body":" Cloud2Gether Documentation Get Started API Reference The Agentic DevOps Platform â€” Automate your infrastructure with AI-powered agents\nCloud2Gether brings the power of AI agents to your DevOps workflows. Deploy, manage, and scale your infrastructure with intelligent automation that learns and adapts.\nAI-Powered Agents Intelligent agents that understand your infrastructure and automate complex operations with natural language commands.\nRead more\nRapid Deployment Get started in minutes. Connect your cloud providers and let Cloud2Gether agents handle the complexity.\nRead more\nEnterprise Security Built-in security best practices, role-based access control, and comprehensive audit logging.\nRead more\nWhy Cloud2Gether? Traditional DevOps requires specialized knowledge and manual configuration. Cloud2Gether's agentic approach lets you describe what you want in plain language, and our AI agents figure out how to make it happen. Natural Language Operations Tell agents what you need: â€œDeploy my app to production with zero downtimeâ€ â€” they handle the rest.\nContinuous Optimization Agents continuously monitor and optimize your infrastructure for cost, performance, and reliability.\nMulti-Cloud Native Seamlessly work across AWS, Azure, GCP, and on-premises infrastructure with a unified experience.\n","categories":"","description":"","excerpt":" Cloud2Gether Documentation Get Started API Reference The Agentic â€¦","ref":"/en/","tags":"","title":"Cloud2Gether Documentation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"}]